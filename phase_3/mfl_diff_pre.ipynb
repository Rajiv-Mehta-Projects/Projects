{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flwr-datasets"
      ],
      "metadata": {
        "id": "33L4ZaR8LyoP",
        "outputId": "002e45f8-e96f-4803-b90c-97e030a94075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "33L4ZaR8LyoP",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flwr-datasets\n",
            "  Downloading flwr_datasets-0.5.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting datasets<=3.1.0,>=2.14.6 (from flwr-datasets)\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.5 in /usr/local/lib/python3.11/dist-packages (from flwr-datasets) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from flwr-datasets) (2.0.2)\n",
            "Requirement already satisfied: seaborn<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from flwr-datasets) (0.13.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from flwr-datasets) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (0.70.15)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=3.1.0,>=2.14.6->flwr-datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets<=3.1.0,>=2.14.6->flwr-datasets) (4.13.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<=3.1.0,>=2.14.6->flwr-datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<=3.1.0,>=2.14.6->flwr-datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.5->flwr-datasets) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr-datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr-datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr-datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr-datasets) (2025.4.26)\n",
            "Downloading flwr_datasets-0.5.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.0/87.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets, flwr-datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.9.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 flwr-datasets-0.5.0 fsspec-2024.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flwr[simulation]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpI_qFIEXdhT",
        "outputId": "48e80de4-a4f4-474a-a5f4-a9826e1a4927"
      },
      "id": "WpI_qFIEXdhT",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flwr[simulation]\n",
            "  Downloading flwr-1.18.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting cryptography<45.0.0,>=44.0.1 (from flwr[simulation])\n",
            "  Downloading cryptography-44.0.3-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.71.0)\n",
            "Collecting iterators<0.0.3,>=0.0.2 (from flwr[simulation])\n",
            "  Downloading iterators-0.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.0.2)\n",
            "Collecting pathspec<0.13.0,>=0.12.1 (from flwr[simulation])\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting protobuf<5.0.0,>=4.21.6 (from flwr[simulation])\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting pycryptodome<4.0.0,>=3.18.0 (from flwr[simulation])\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (6.0.2)\n",
            "Collecting ray==2.31.0 (from flwr[simulation])\n",
            "  Downloading ray-2.31.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (13.9.4)\n",
            "Collecting tomli<3.0.0,>=2.0.1 (from flwr[simulation])\n",
            "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting tomli-w<2.0.0,>=1.0.0 (from flwr[simulation])\n",
            "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting typer<0.13.0,>=0.12.5 (from flwr[simulation])\n",
            "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (8.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (24.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<45.0.0,>=44.0.1->flwr[simulation]) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (2.19.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (4.13.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr[simulation]) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr[simulation]) (0.1.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.24.0)\n",
            "Downloading ray-2.31.0-cp311-cp311-manylinux2014_x86_64.whl (66.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cryptography-44.0.3-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iterators-0.0.2-py3-none-any.whl (3.9 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flwr-1.18.0-py3-none-any.whl (540 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.0/540.0 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tomli-w, tomli, pycryptodome, protobuf, pathspec, iterators, cryptography, typer, ray, flwr\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 43.0.3\n",
            "    Uninstalling cryptography-43.0.3:\n",
            "      Successfully uninstalled cryptography-43.0.3\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.15.3\n",
            "    Uninstalling typer-0.15.3:\n",
            "      Successfully uninstalled typer-0.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 44.0.3 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cryptography-44.0.3 flwr-1.18.0 iterators-0.0.2 pathspec-0.12.1 protobuf-4.25.7 pycryptodome-3.23.0 ray-2.31.0 tomli-2.2.1 tomli-w-1.2.0 typer-0.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E40eYz4JXzLR",
        "outputId": "56fca9be-7098-4ec3-e412-06beae7899bb"
      },
      "id": "E40eYz4JXzLR",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade cryptography==44.0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceeyM19iYBE3",
        "outputId": "49abd1b2-c018-4182-8e0b-abce144ffc11"
      },
      "id": "ceeyM19iYBE3",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cryptography==44.0.1\n",
            "  Downloading cryptography-44.0.1-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography==44.0.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography==44.0.1) (2.22)\n",
            "Downloading cryptography-44.0.1-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cryptography\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 44.0.3\n",
            "    Uninstalling cryptography-44.0.3:\n",
            "      Successfully uninstalled cryptography-44.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 44.0.1 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cryptography-44.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "af6dc669",
      "metadata": {
        "id": "af6dc669"
      },
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from collections import Counter, OrderedDict\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# Third-party libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# Hugging Face datasets\n",
        "import datasets\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Flower\n",
        "from flwr.client import NumPyClient, ClientApp\n",
        "from flwr.common import NDArrays, Scalar, Context, Metrics, ndarrays_to_parameters\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr_datasets.partitioner import Partitioner\n",
        "from flwr_datasets.visualization import plot_label_distributions\n",
        "\n",
        "# Kaggle (if used to pull data)\n",
        "import kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root = kagglehub.dataset_download(\"murtozalikhon/brain-tumor-multimodal-image-ct-and-mri\")\n",
        "print(\"Path to dataset files:\", root)"
      ],
      "metadata": {
        "id": "Yu0iAOBRwKV-",
        "outputId": "5837ab69-fa79-463f-acbe-97f44509f0bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Yu0iAOBRwKV-",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/brain-tumor-multimodal-image-ct-and-mri\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ManualPartitioner(Partitioner):\n",
        "    def __init__(self, partitions: Dict[int, list]):\n",
        "        super().__init__()\n",
        "        self.partitions = partitions  # Maps partition_id -> list of indices\n",
        "        self._dataset: Dataset = None\n",
        "\n",
        "    @property\n",
        "    def num_partitions(self) -> int:\n",
        "        return len(self.partitions)\n",
        "\n",
        "    @property\n",
        "    def dataset(self) -> Dataset:\n",
        "        return self._dataset\n",
        "\n",
        "    @dataset.setter\n",
        "    def dataset(self, dataset: Dataset) -> None:\n",
        "        if not isinstance(dataset, Dataset):\n",
        "            raise TypeError(\"Only Hugging Face datasets.Dataset is supported.\")\n",
        "        self._dataset = dataset\n",
        "\n",
        "    def load_partition(self, partition_id: int) -> Dataset:\n",
        "        if self._dataset is None:\n",
        "            raise ValueError(\"Dataset not assigned to the partitioner.\")\n",
        "        indices = self.partitions.get(partition_id)\n",
        "        if indices is None:\n",
        "            raise ValueError(f\"No partition found for partition_id {partition_id}.\")\n",
        "        return self._dataset.select(indices)\n"
      ],
      "metadata": {
        "id": "_L5T2Tsu1w6I"
      },
      "id": "_L5T2Tsu1w6I",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MultiModalDataset(Dataset):\n",
        "    def __init__(self, root1, root2, transform=None, input_size=64, use_cache=True):\n",
        "        self.transform = transform\n",
        "        self.input_size = input_size\n",
        "        self.use_cache = use_cache\n",
        "        self.cache = {}  # Dictionary for caching images\n",
        "\n",
        "        # Load modality 1\n",
        "        self.mod1_dataset = ImageFolder(root1)\n",
        "        self.mod1_samples = self.mod1_dataset.samples  # List of (path, label)\n",
        "\n",
        "        # Load modality 2\n",
        "        self.mod2_dataset = ImageFolder(root2)\n",
        "        self.mod2_samples = self.mod2_dataset.samples\n",
        "\n",
        "        # Construct unified sample list with modality index\n",
        "        self.id = 0\n",
        "        self.samples = []\n",
        "        for path, label in self.mod1_samples:\n",
        "            self.samples.append((path, label, 0, self.id))  # 0 for modality 1\n",
        "\n",
        "            image = Image.open(path).convert(\"RGB\")\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            else:\n",
        "                image = transforms.ToTensor()(image)\n",
        "            if self.use_cache:\n",
        "                self.cache[path] = image\n",
        "\n",
        "            self.id += 1\n",
        "\n",
        "        for path, label in self.mod2_samples:\n",
        "            self.samples.append((path, label, 1, self.id))  # 1 for modality 2\n",
        "\n",
        "            image = Image.open(path).convert(\"RGB\")\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            else:\n",
        "                image = transforms.ToTensor()(image)\n",
        "            if self.use_cache:\n",
        "                self.cache[path] = image\n",
        "\n",
        "            self.id += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label, modality_index, id = self.samples[idx]\n",
        "\n",
        "        image = self.cache[path]\n",
        "        zeros = torch.zeros(3, self.input_size, self.input_size)\n",
        "\n",
        "        if modality_index == 0:\n",
        "            image1 = image\n",
        "            image2 = zeros\n",
        "        elif modality_index == 1:\n",
        "            image1 = zeros\n",
        "            image2 = image\n",
        "\n",
        "        return image1, image2, label"
      ],
      "metadata": {
        "id": "2wAMsngI2mK8"
      },
      "id": "2wAMsngI2mK8",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = root + '/Dataset'\n",
        "\n",
        "modalities = [\n",
        "    'Brain Tumor CT scan Images',\n",
        "    'Brain Tumor MRI images'\n",
        "]\n",
        "\n",
        "modalities_path = [os.path.join(dataset_path, i) for i in modalities]\n",
        "print(modalities_path)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "w_u2XPNB3aJ5",
        "outputId": "ce29fc11-7144-469b-d8a0-fb7cbc2d440a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "w_u2XPNB3aJ5",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/kaggle/input/brain-tumor-multimodal-image-ct-and-mri/Dataset/Brain Tumor CT scan Images', '/kaggle/input/brain-tumor-multimodal-image-ct-and-mri/Dataset/Brain Tumor MRI images']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_ds = MultiModalDataset(\n",
        "    modalities_path[0],\n",
        "    modalities_path[1],\n",
        "    transform=transform,\n",
        "    use_cache=True)\n",
        "\n",
        "main_ds.__len__()"
      ],
      "metadata": {
        "id": "hFcJpry940wf",
        "outputId": "743b4b0b-abce-4c4b-fbaa-65d1f1e46ff6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hFcJpry940wf",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9618"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modality_map = [modality for _, _, modality, _ in main_ds.samples]"
      ],
      "metadata": {
        "id": "jCNoC7Wc5oUs"
      },
      "id": "jCNoC7Wc5oUs",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modality_map_dict = {idx: modality for idx, (_, _, modality, _) in enumerate(main_ds.samples)}\n",
        "\n",
        "partition_0 = [i for i, m in modality_map_dict.items() if m == 0]\n",
        "partition_1 = [i for i, m in modality_map_dict.items() if m == 1]\n",
        "\n",
        "manual_partitions = {\n",
        "    0: partition_0,\n",
        "    1: partition_1,\n",
        "}"
      ],
      "metadata": {
        "id": "rtPX9ow26U9U"
      },
      "id": "rtPX9ow26U9U",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Extract data from your OneForTwoDataset\n",
        "data = []\n",
        "\n",
        "for path, label, modality, id in main_ds.samples:\n",
        "    data.append({\n",
        "        \"image\": path,\n",
        "        \"label\": label,\n",
        "        \"modality\": modality,\n",
        "        \"id\": id\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "hf_dataset = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "id": "aiVKJMC29od8"
      },
      "id": "aiVKJMC29od8",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "partitioner = ManualPartitioner(partitions=manual_partitions)\n",
        "partitioner.dataset = hf_dataset\n",
        "\n",
        "# Load a specific partition\n",
        "partition_0 = partitioner.load_partition(0)\n",
        "print(partition_0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM_rGG-eNmLp",
        "outputId": "23a33b98-5d5c-4cc2-cb69-4e226629422a"
      },
      "id": "iM_rGG-eNmLp",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['image', 'label', 'modality', 'id'],\n",
            "    num_rows: 4618\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax, df = plot_label_distributions(\n",
        "    partitioner,\n",
        "    label_name=\"label\",\n",
        "    plot_type=\"bar\",\n",
        "    size_unit=\"absolute\",\n",
        "    partition_id_axis=\"x\",\n",
        "    legend=True,\n",
        "    verbose_labels=True,\n",
        "    max_num_partitions=30,  # Note we are only showing the first 30 so the plot remains readable\n",
        "    title=\"Per Partition Labels Distribution\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "h5B2S6x6Ms8A",
        "outputId": "94388ce5-21ce-43b1-f1d3-afd10d6f8219"
      },
      "id": "h5B2S6x6Ms8A",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/flwr_datasets/metrics/utils.py:130: UserWarning: The verbose names can not be established. The column specified by 'column_name' needs to be of type 'ClassLabel' to create a verbose names. The available names will used.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class HFDatasetWrapper(Dataset):\n",
        "    def __init__(self, hf_dataset, ds, transform=None):\n",
        "        self.dataset = hf_dataset\n",
        "        self.cached = ds\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        item = self.dataset[idx]\n",
        "        #print(item['id'])\n",
        "\n",
        "        raw_item = self.cached[item['id']]\n",
        "\n",
        "        image1 = raw_item[0]\n",
        "        image2 = raw_item[1]\n",
        "        result = (image1, image2, item[\"label\"])\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "RxI0e2GPThxF"
      },
      "id": "RxI0e2GPThxF",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "def get_dataloaders(dataset, batch_size: int = 32):\n",
        "\n",
        "    partition_train_val = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "    train_dataset = HFDatasetWrapper(\n",
        "        partition_train_val[\"train\"], main_ds)\n",
        "    val_dataset = HFDatasetWrapper(\n",
        "        partition_train_val[\"test\"], main_ds)\n",
        "\n",
        "    # Construct PyTorch dataloaders\n",
        "    trainloader = DataLoader(\n",
        "        train_dataset, batch_size=batch_size,\n",
        "        shuffle=True, generator=g, num_workers=0)\n",
        "    testloader = DataLoader(\n",
        "        val_dataset, batch_size=batch_size,\n",
        "        num_workers=0)\n",
        "\n",
        "    return trainloader, testloader"
      ],
      "metadata": {
        "id": "jQxYH2ZuShu3"
      },
      "id": "jQxYH2ZuShu3",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "partition_0 = partitioner.load_partition(0)\n",
        "#partition_train_val = partition_0.train_test_split(test_size=0.2, seed=42)\n",
        "#partition_train_val['test']\n",
        "\n",
        "trainloader, testloader = get_dataloaders(partition_0)\n",
        "\n",
        "for images1, images2, labels in tqdm(trainloader):\n",
        "    continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG-KONdMUaaF",
        "outputId": "9337183e-55c8-4ab3-f373-0e7645f920e5"
      },
      "id": "cG-KONdMUaaF",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 116/116 [00:00<00:00, 277.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, id, trainloader, optimizer, device):\n",
        "\n",
        "    #train_time = time.time()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    net.to(device)\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "\n",
        "    for images1, images2, labels in trainloader:\n",
        "        #images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "        images1, images2, labels = images1.to(device), images2.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images1, images2)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += labels.size(0)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    #print(f\"Loss: {running_loss/len(trainloader):.4f}\")\n",
        "\n",
        "    #train_time = time.time() - train_time\n",
        "    #print(f\"Training time: {train_time:.2f} seconds\")\n",
        "\n",
        "    return running_loss / len(trainloader)\n",
        "\n",
        "def test(net, id, testloader, device):\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    correct, loss = 0, 0.0\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images1, images2, labels in testloader:\n",
        "            #images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "            images1, images2, labels = images1.to(device), images2.to(device), labels.to(device)\n",
        "            outputs = net(images1, images2)\n",
        "\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return loss / len(testloader), accuracy"
      ],
      "metadata": {
        "id": "msEQl21PN4IB"
      },
      "id": "msEQl21PN4IB",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNNBranch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNNBranch, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),  # Input: 3xHxW\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # H/2 x W/2\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # H/4 x W/4\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))  # Output shape: (64, 1, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x.view(x.size(0), -1)  # Flatten to (batch_size, 64)\n",
        "\n",
        "class DualModalitySimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(DualModalitySimpleCNN, self).__init__()\n",
        "        self.branch1 = SimpleCNNBranch()\n",
        "        self.branch2 = SimpleCNNBranch()\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64 * 2, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        f1 = self.branch1(x1)\n",
        "        f2 = self.branch2(x2)\n",
        "        fused = torch.cat((f1, f2), dim=1)\n",
        "        return self.classifier(fused)\n",
        "\n",
        "class SingleModalitySimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SingleModalitySimpleCNN, self).__init__()\n",
        "        self.feature_extractor = SimpleCNNBranch()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extractor(x)\n",
        "        return self.classifier(features)"
      ],
      "metadata": {
        "id": "Snb8gs6QaiJk"
      },
      "id": "Snb8gs6QaiJk",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, trainloader, valloader, id) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.id = id\n",
        "        self.model = DualModalitySimpleCNN(num_classes=2)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        #print(f\"Training on device: {self.device}\")\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "\n",
        "        set_params(self.model, parameters)\n",
        "        optim = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
        "        train(self.model, self.id, self.trainloader, optim, self.device)\n",
        "\n",
        "        return get_params(self.model), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "\n",
        "        set_params(self.model, parameters)\n",
        "        loss, accuracy = test(self.model, self.id, self.valloader, self.device)\n",
        "\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": accuracy, \"loss\": loss, 'id': self.id}\n",
        "\n",
        "\n",
        "def set_params(model, parameters):\n",
        "\n",
        "    params_dict = zip(model.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.from_numpy(v) for k, v in params_dict})\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def get_params(model):\n",
        "    return [val.cpu().numpy() for _, val in model.state_dict().items()]"
      ],
      "metadata": {
        "id": "9S2XdLK0XANx"
      },
      "id": "9S2XdLK0XANx",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def client_fn(context: Context):\n",
        "    \"\"\"Returns a FlowerClient containing its data partition.\"\"\"\n",
        "\n",
        "    partition_id = int(context.node_config[\"partition-id\"])\n",
        "    partition = partitioner.load_partition(partition_id)\n",
        "    #partition_train_val = partition.train_test_split(test_size=0.2, seed=42)\n",
        "    trainloader, testloader = get_dataloaders(partition, batch_size=32)\n",
        "\n",
        "    return FlowerClient(trainloader=trainloader, valloader=testloader, id=partition_id).to_client()\n",
        "\n",
        "client_app = ClientApp(client_fn=client_fn)"
      ],
      "metadata": {
        "id": "yeuK2YE2XWXe"
      },
      "id": "yeuK2YE2XWXe",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_metrics = []\n",
        "\n",
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    client_metrics.append(metrics)\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "ny69gb6LZbUz"
      },
      "id": "ny69gb6LZbUz",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rounds = 100\n",
        "\n",
        "def server_fn(context: Context):\n",
        "\n",
        "    model = DualModalitySimpleCNN(num_classes=2)\n",
        "    ndarrays = get_params(model)\n",
        "\n",
        "    global_model_init = ndarrays_to_parameters(ndarrays)\n",
        "\n",
        "    strategy = FedAvg(\n",
        "        fraction_fit=1.0,  # 10% clients sampled each round to do fit()\n",
        "        fraction_evaluate=1.0,  # 50% clients sample each round to do evaluate()\n",
        "        evaluate_metrics_aggregation_fn=weighted_average,  # callback defined earlier\n",
        "        initial_parameters=global_model_init,  # initialised global model\n",
        "    )\n",
        "\n",
        "    config = ServerConfig(num_rounds=num_rounds)\n",
        "\n",
        "    return ServerAppComponents(strategy=strategy, config=config)\n",
        "\n",
        "\n",
        "server_app = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "uKUtxF4YZc34"
      },
      "id": "uKUtxF4YZc34",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "backend_config = {\n",
        "    \"client_resources\": {\n",
        "        \"num_gpus\": 1.0,\n",
        "        \"num_cpus\": 8.0},\n",
        "    \"äctor\": {\n",
        "        \"actor_reuse\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "run_simulation(\n",
        "    client_app=client_app,\n",
        "    server_app=server_app,\n",
        "    num_supernodes=2,\n",
        "    backend_config=backend_config\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total simulation time: {total_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "_e53nZcpZetW",
        "outputId": "e974682a-3506-42a9-9233-a6552f2af0f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_e53nZcpZetW",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=100, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[36m(pid=7776)\u001b[0m 2025-05-20 14:52:27.492342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=7776)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=7776)\u001b[0m E0000 00:00:1747752747.514765    7776 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=7776)\u001b[0m E0000 00:00:1747752747.521600    7776 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(ClientAppActor pid=7776)\u001b[0m /usr/local/lib/python3.11/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[36m(ClientAppActor pid=7776)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[36m(ClientAppActor pid=7776)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[36m(ClientAppActor pid=7776)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[36m(ClientAppActor pid=7776)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[36m(ClientAppActor pid=7776)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 11]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 12]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 13]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 14]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 15]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 16]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 17]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 18]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 19]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 20]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 21]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 22]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 23]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 24]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 25]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 26]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 27]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 28]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 29]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 30]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 31]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 32]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 33]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 34]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 35]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 36]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 37]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 38]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 39]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 40]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 41]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 42]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 43]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 44]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 45]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 46]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 47]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 48]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 49]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 50]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 51]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 52]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 53]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 54]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 55]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 56]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 57]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 58]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 59]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 60]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 61]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 62]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 63]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 64]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 65]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 66]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 67]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 68]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 69]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 70]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 71]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 72]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 73]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 74]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 75]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 76]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 77]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 78]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 79]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 80]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 81]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 82]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 83]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 84]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 85]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 86]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 87]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 88]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 89]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 90]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 91]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 92]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 93]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 94]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 95]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 96]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 97]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 98]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 99]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 100]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 100 round(s) in 1294.58s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.6513887497245289\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.6026293889420932\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.5772091355480131\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.5611645105432291\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.552140939919675\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.5838126931034151\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.5930623343733491\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.5913987824174224\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.5706712828307855\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.5550271465641553\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 11: 0.5323687735639635\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 12: 0.46419341324782765\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 13: 0.44214541672683155\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 14: 0.39953033186373166\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 15: 0.37227032101545177\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 16: 0.34358011430404223\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 17: 0.3282465443747943\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 18: 0.30792998534734134\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 19: 0.2804478668287152\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 20: 0.27308260246378474\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 21: 0.26716144040959783\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 22: 0.25543546017076146\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 23: 0.24917127656154944\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 24: 0.24230755816717617\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 25: 0.23525415397569782\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 26: 0.22828127419362304\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 27: 0.21958350084844183\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 28: 0.21010568157815543\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 29: 0.20865369044610713\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 30: 0.21587229642223138\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 31: 0.21081198251149694\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 32: 0.21990166854907256\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 33: 0.21780189480937895\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 34: 0.20841480040403662\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 35: 0.19439240508392208\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 36: 0.1973646950037753\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 37: 0.2014527042381099\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 38: 0.19539266592655025\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 39: 0.19808774368196239\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 40: 0.2094971748282675\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 41: 0.20122091643145826\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 42: 0.1843134607875445\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 43: 0.18822961169310282\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 44: 0.18563594748495055\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 45: 0.17934363411708934\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 46: 0.19166617290895493\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 47: 0.1842400937906054\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 48: 0.1791240861181353\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 49: 0.16341164280645182\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 50: 0.14870864923921276\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 51: 0.1440573578669888\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 52: 0.1419528928722759\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 53: 0.13808372769443716\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 54: 0.13260828972351354\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 55: 0.13072170877493308\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 56: 0.12902138295171203\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 57: 0.13846423156315185\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 58: 0.12586558152173385\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 59: 0.12414016305911736\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 60: 0.11815985762437836\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 61: 0.11786174551263208\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 62: 0.118824979443042\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 63: 0.11459057109399898\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 64: 0.11037187308805887\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 65: 0.10958834972660073\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 66: 0.11090052263719626\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 67: 0.11302595805437839\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 68: 0.10764538876895534\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 69: 0.10902264598207395\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 70: 0.10393994698514704\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 71: 0.10733678772831794\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 72: 0.10741132496260718\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 73: 0.10755074992165213\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 74: 0.11103317849948759\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 75: 0.10769900584929303\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 76: 0.1080435967973632\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 77: 0.11167322583191219\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 78: 0.10703075904643437\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 79: 0.10564490335947666\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 80: 0.10703808334121695\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 81: 0.10907419088495071\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 82: 0.11038501075178873\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 83: 0.1014625791261797\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 84: 0.10400855274046542\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 85: 0.10767458517440275\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 86: 0.10430212421953435\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 87: 0.10914862046751087\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 88: 0.10317730641786436\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 89: 0.09823910118706647\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 90: 0.104743486178703\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 91: 0.09892976253491934\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 92: 0.0994653026497022\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 93: 0.09500781451275603\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 94: 0.09726126057660726\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 95: 0.10146549786822717\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 96: 0.10066249183394381\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 97: 0.09887178940698504\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 98: 0.0967926363628663\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 99: 0.09846080657949702\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 100: 0.09530969217541765\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.6669932581080122),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.7226608473493719),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.7187462919594068),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.7273614363778298),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.7628320204385778),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (6, 0.7492928819814065),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (7, 0.7283999716130864),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (8, 0.7296103896103896),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (9, 0.735451422894046),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (10, 0.7406872471790505),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (11, 0.7505436093960683),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (12, 0.7906554538357817),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (13, 0.7989884323326946),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (14, 0.817470584060748),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (15, 0.8314329714001845),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (16, 0.8479276133702363),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (17, 0.8530525867575047),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (18, 0.8700315094741324),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (19, 0.8834693066496345),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (20, 0.8850733092044568),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (21, 0.888200695479384),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (22, 0.897007877368533),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (23, 0.8944554680292385),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (24, 0.8955046483571073),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (25, 0.8997013696685827),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (26, 0.9038376268540204),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (27, 0.9121907600596125),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (28, 0.9194241714569584),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (29, 0.9184354552551274),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (30, 0.9148741750053226),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (31, 0.9164580228514655),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (32, 0.9144503583847846),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (33, 0.915489461358314),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (34, 0.9216837697821303),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (35, 0.9242462564757647),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (36, 0.9268792846497764),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (37, 0.9237720530835285),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (38, 0.9248010787027181),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (39, 0.923247462919594),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (40, 0.9155499254843517),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (41, 0.919151515151515),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (42, 0.9294518486977502),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (43, 0.9274038748137108),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (44, 0.9289675679511745),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (45, 0.9315401319991484),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (46, 0.9253559009296713),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (47, 0.9279486196863245),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (48, 0.9325792349726776),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (49, 0.9367054148037753),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (50, 0.9434243133915265),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (51, 0.943888439429423),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (52, 0.9464710808317366),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (53, 0.9506274927258533),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (54, 0.9527258533815911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (55, 0.952221417926336),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (56, 0.9553689589099426),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (57, 0.9497193953587396),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (58, 0.9595253708040592),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (59, 0.957951600312256),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (60, 0.9615531899794195),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (61, 0.9626124476616279),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (62, 0.9626023703072882),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (63, 0.9636414732808174),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (64, 0.9641459087360726),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (65, 0.9656995245191967),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (66, 0.9641761407990916),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (67, 0.9620979348520332),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (68, 0.9667386274927259),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (69, 0.9662341920374707),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (70, 0.9667688595557448),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (71, 0.9667789369100844),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (72, 0.9678180398836136),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (73, 0.9677978851749344),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (74, 0.9652051664182812),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (75, 0.9667688595557448),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (76, 0.9657398339365552),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (77, 0.9630967284082037),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (78, 0.9673136044283585),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (79, 0.9688672202114825),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (80, 0.9631269604712227),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (81, 0.9647611950890639),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (82, 0.9646805762543468),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (83, 0.9683829394649066),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (84, 0.9673035270740189),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (85, 0.9641862181534312),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (86, 0.9683627847562274),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (87, 0.9641761407990916),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (88, 0.9641761407990916),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (89, 0.9647208856717053),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (90, 0.963116883116883),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (91, 0.9657196792278759),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (92, 0.9641559860904123),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (93, 0.96625434674615),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (94, 0.964196295507771),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (95, 0.9647108083173657),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (96, 0.9678281172379533),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (97, 0.9678482719466327),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (98, 0.968857142857143),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (99, 0.9709555035128806),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (100, 0.9647208856717053)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total simulation time: 1297.13 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client_accs = [[] for _ in range(len(client_metrics[0]))]  # List of lists to store accuracies for each client\n",
        "client_losses = [[] for _ in range(len(client_metrics[0]))]  # List of lists to store losses for each client\n",
        "\n",
        "# Loop through each round of experiment (outer list)\n",
        "for round_data in client_metrics:\n",
        "    # Loop through each client (inner list)\n",
        "    for client_idx, (_, metrics) in enumerate(round_data):\n",
        "        # Append the accuracy and loss for the current client in this round\n",
        "        client_accs[metrics['id']].append(metrics['accuracy'])\n",
        "        client_losses[metrics['id']].append(metrics['loss'])"
      ],
      "metadata": {
        "id": "DcQcXDRTZ7Oy"
      },
      "id": "DcQcXDRTZ7Oy",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, client in enumerate(client_accs):\n",
        "    plt.plot(client, label='client ' + str(i))\n",
        "plt.title(\"Acc vs iteration\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Acc\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bcGy8XndgOew",
        "outputId": "991941ef-c90f-44bf-ef6c-a6d2819c0ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "id": "bcGy8XndgOew",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdWpJREFUeJzt3Xd8VFX6x/HPTHoPJRUCoRfpVZqisKIgdhdZVxB7QVR+rop9bair2BV7xRVRLCuKYCiKIr33ToAUQkgnbeb+/riZSUISSGCSyYTv+/WaVya3zTMX5T6c85xzLIZhGIiIiIg0EFZ3ByAiIiLiSkpuREREpEFRciMiIiINipIbERERaVCU3IiIiEiDouRGREREGhQlNyIiItKgKLkRERGRBkXJjYiIiDQoSm5ExKPFx8dz/fXXuzuMGrFYLDzxxBPuDkOkwVJyI9LAvfXWW1gsFvr37+/uUOrE5s2beeKJJ9i7d69b4/jpp5+UwIi4iUVrS4k0bIMGDeLQoUPs3buXHTt20LZtW3eH5FIFBQVYrVZ8fHwA+Prrr7n66qtZuHAhQ4cOdVtcEydO5M0336Syv2Lz8/Px9vbG29vbDZGJNHxquRFpwPbs2cOff/7JtGnTiIiIYMaMGe4OyeX8/PyciU1tys3Nddm1/P39ldiI1CIlNyIN2IwZM2jUqBGjRo3iqquuqjK5ycjI4N577yU+Ph4/Pz+aN2/OuHHjSEtLcx6Tn5/PE088Qfv27fH39ycmJoYrrriCXbt2Vfn5F198Ma1bt65034ABA+jTp4/z9/nz5zN48GDCw8MJDg6mQ4cOPPTQQyf9jmVrbj7++GOuvvpqAM477zwsFgsWi4VFixY5j//5558ZMmQIQUFBhISEMGrUKDZt2lTumtdffz3BwcHs2rWLkSNHEhISwrXXXgvA77//ztVXX02LFi3w8/MjLi6Oe++9l2PHjpU7/8033wRwxmCxWJz7K6u5WbNmDRdddBGhoaEEBwczbNgw/vrrr3LHfPzxx1gsFv744w8mT55MREQEQUFBXH755Rw+fPik90rkTKF/Oog0YDNmzOCKK67A19eXsWPH8vbbb7NixQr69u3rPCYnJ4chQ4awZcsWbrjhBnr16kVaWho//PADBw4coGnTpthsNi6++GISEhK45ppruPvuu8nOzmb+/Pls3LiRNm3aVPr5Y8aMYdy4cRU+c9++ffz111/85z//AWDTpk1cfPHFdOvWjSeffBI/Pz927tzJH3/8UaPve8455zBp0iRee+01HnroITp16gTg/PnZZ58xfvx4RowYwfPPP09eXh5vv/02gwcPZs2aNcTHxzuvVVxczIgRIxg8eDAvvvgigYGBAMyaNYu8vDxuv/12mjRpwvLly3n99dc5cOAAs2bNAuDWW2/l0KFDzJ8/n88+++ykcW/atIkhQ4YQGhrK/fffj4+PD++88w5Dhw5l8eLFFeql7rrrLho1asTjjz/O3r17eeWVV5g4cSIzZ86s0f0SabAMEWmQVq5caQDG/PnzDcMwDLvdbjRv3ty4++67yx332GOPGYAxe/bsCtew2+2GYRjGhx9+aADGtGnTqjymMpmZmYafn5/xf//3f+W2v/DCC4bFYjH27dtnGIZhvPzyywZgHD58uEbf0TAMo2XLlsb48eOdv8+aNcsAjIULF5Y7Ljs72wgPDzduvvnmctuTk5ONsLCwctvHjx9vAMaDDz5Y4fPy8vIqbJs6dWq572MYhnHnnXcaVf0VCxiPP/648/fLLrvM8PX1NXbt2uXcdujQISMkJMQ455xznNs++ugjAzCGDx9e7r7fe++9hpeXl5GRkVHp54mcadQtJdJAzZgxg6ioKM477zzA7AoZM2YMX375JTabzXncN998Q/fu3bn88ssrXMPRlfLNN9/QtGlT7rrrriqPqUxoaCgXXXQRX331VbnC2pkzZ3L22WfTokULAMLDwwH4/vvvsdvtNf+y1TB//nwyMjIYO3YsaWlpzpeXlxf9+/dn4cKFFc65/fbbK2wLCAhwvs/NzSUtLY2BAwdiGAZr1qypcVw2m4158+Zx2WWXlevCi4mJ4R//+AdLliwhKyur3Dm33HJLufs+ZMgQbDYb+/btq/HnizRESm5EGiCbzcaXX37Jeeedx549e9i5cyc7d+6kf//+pKSkkJCQ4Dx2165ddOnS5YTX27VrFx06dDilItgxY8aQmJjI0qVLnddatWoVY8aMKXfMoEGDuOmmm4iKiuKaa67hq6++cmmis2PHDgDOP/98IiIiyr3mzZtHampqueO9vb1p3rx5hevs37+f66+/nsaNGxMcHExERATnnnsuAJmZmTWO6/Dhw+Tl5dGhQ4cK+zp16oTdbicxMbHcdkdS6NCoUSMAjh49WuPPF2mIVHMj0gAtWLCApKQkvvzyS7788ssK+2fMmMEFF1xQJ7GMHj2awMBAvvrqKwYOHMhXX32F1Wp1Fv6C2Rry22+/sXDhQubMmcPcuXOZOXMm559/PvPmzcPLy+u043AkSp999hnR0dEV9h+fuPn5+WG1lv/3n81m429/+xvp6ek88MADdOzYkaCgIA4ePMj1119fa61Ox6vqfhia2UMEUHIj0iDNmDGDyMhI54idsmbPns23337L9OnTCQgIoE2bNmzcuPGE12vTpg3Lli2jqKioxsOug4KCuPjii5k1axbTpk1j5syZDBkyhNjY2HLHWa1Whg0bxrBhw5g2bRrPPvssDz/8MAsXLmT48OHV/ryquskcRc+RkZE1ul5ZGzZsYPv27XzyySeMGzfOuX3+/PnVjuN4ERERBAYGsm3btgr7tm7ditVqJS4u7pTiFTlTqVtKpIE5duwYs2fP5uKLL+aqq66q8Jo4cSLZ2dn88MMPAFx55ZWsW7eOb7/9tsK1HC0BV155JWlpabzxxhtVHnMiY8aM4dChQ7z//vusW7euXJcUQHp6eoVzevToAZiT9NVEUFAQYA5vL2vEiBGEhoby7LPPUlRUVOG86gyldrSYlP3OhmHw6quvVjuOyq55wQUX8P3335ebVTklJYUvvviCwYMHExoaetLYRKSUWm5EGpgffviB7OxsLrnkkkr3n3322c4J/caMGcO//vUv56y+N9xwA7179yY9PZ0ffviB6dOn0717d8aNG8enn37K5MmTWb58OUOGDCE3N5dff/2VO+64g0svvfSEMTnmirnvvvvw8vLiyiuvLLf/ySef5LfffmPUqFG0bNmS1NRU3nrrLZo3b87gwYNr9P179OiBl5cXzz//PJmZmfj5+XH++ecTGRnJ22+/zXXXXUevXr245ppriIiIYP/+/cyZM4dBgwZVmryV1bFjR9q0acN9993HwYMHCQ0N5Ztvvqm01qV3794ATJo0iREjRuDl5cU111xT6XWffvpp5zw/d9xxB97e3rzzzjsUFBTwwgsv1Oj7iwgaCi7S0IwePdrw9/c3cnNzqzzm+uuvN3x8fIy0tDTDMAzjyJEjxsSJE41mzZoZvr6+RvPmzY3x48c79xuGOQT64YcfNlq1amX4+PgY0dHRxlVXXVVu+PKJXHvttc5hzMdLSEgwLr30UiM2Ntbw9fU1YmNjjbFjxxrbt28/6XWPHwpuGIbx3nvvGa1btza8vLwqDAtfuHChMWLECCMsLMzw9/c32rRpY1x//fXGypUrnceMHz/eCAoKqvTzNm/ebAwfPtwIDg42mjZtatx8883GunXrDMD46KOPnMcVFxcbd911lxEREWFYLJZyw8I5bii4YRjG6tWrjREjRhjBwcFGYGCgcd555xl//vlnuWMcQ8FXrFhRbvvChQsrHf4ucqbS2lIiIiLSoKjmRkRERBoUJTciIiLSoCi5ERERkQZFyY2IiIg0KG5Nbn777TdGjx5NbGwsFouF77777qTnLFq0iF69euHn50fbtm35+OOPaz1OERER8RxuTW5yc3Pp3r17pbOoVmbPnj2MGjWK8847j7Vr13LPPfdw00038csvv9RypCIiIuIp6s1QcIvFwrfffstll11W5TEPPPAAc+bMKTdV/DXXXENGRgZz586t1ufY7XYOHTpESEhItadHFxEREfcyDIPs7GxiY2MrrPt2PI+aoXjp0qUV1oQZMWIE99xzT5XnFBQUlJu+/eDBg3Tu3Lm2QhQREZFalJiYSPPmzU94jEclN8nJyURFRZXbFhUVRVZWFseOHSMgIKDCOVOnTuXf//53he2JiYlar0VERMRDZGVlERcXR0hIyEmP9ajk5lRMmTKFyZMnO3933JzQ0FAlNyIiIh6mOiUlHpXcREdHk5KSUm5bSkoKoaGhlbbaAPj5+eHn51cX4YmIiEg94FHz3AwYMICEhIRy2+bPn8+AAQPcFJGIiIjUN25NbnJycli7di1r164FzKHea9euZf/+/YDZpTRu3Djn8bfddhu7d+/m/vvvZ+vWrbz11lt89dVX3Hvvve4IX0REROoht3ZLrVy5kvPOO8/5u6M2Zvz48Xz88cckJSU5Ex2AVq1aMWfOHO69915effVVmjdvzvvvv8+IESNcHpvNZqOoqMjl15Wa8fHxwcvLy91hiIiIB6k389zUlaysLMLCwsjMzKy0oNgwDJKTk8nIyKj74KRS4eHhREdHa14iEZEz2Mme32V5VEFxXXAkNpGRkQQGBuqB6kaGYZCXl0dqaioAMTExbo5IREQ8gZKbMmw2mzOxadKkibvDEXCOgktNTSUyMlJdVCIiclIeNVqqtjlqbAIDA90ciZTl+PNQDZSIiFSHkptKqCuqftGfh4iI1ISSGxEREWlQlNycAfbu3YvFYnHOJ7Ro0SIsFotGhImISIOk5OYMNHDgQJKSkggLC3PZNY9PoE5k//79jBo1isDAQCIjI/nXv/5FcXGxy2IREZEzm0ZLnYF8fX2Jjo52y2fbbDZGjRpFdHQ0f/75J0lJSYwbNw4fHx+effZZt8QkIlIlWxFgAS89LitlGFCUB75B7o6kHLXcNBB2u50XXniBtm3b4ufnR4sWLXjmmWcqPbaybqklS5YwZMgQAgICiIuLY9KkSeTm5jr3x8fH8+yzz3LDDTcQEhJCixYtePfdd537W7VqBUDPnj2xWCwMHTq00s+eN28emzdv5vPPP6dHjx5cdNFFPPXUU7z55psUFhae/o0QEXGVwjx4fxi82A62/uTuaOqfPb/Dm/3hhTaw6Vt3R1OOkpuTMAyDvMJit7xqMnn0lClTeO6553j00UfZvHkzX3zxBVFRUdU6d9euXVx44YVceeWVrF+/npkzZ7JkyRImTpxY7riXXnqJPn36sGbNGu644w5uv/12tm3bBsDy5csB+PXXX0lKSmL27NmVftbSpUvp2rVrudhGjBhBVlYWmzZtqvb3FRE5IbvdbFWoimHAX2/DgqfBVkW3+KJnIWkdHEuHL8fCr09UfWxZqVvh29tgz2+nFLrb2Ypg9yL4+QH4+gZY/SnkHC7dn3PY/H6fXAxp26D4GMyaACs/clvIx1M720kcK7LR+bFf3PLZm58cQaDvyf+IsrOzefXVV3njjTcYP348AG3atGHw4MHV+pypU6dy7bXXcs899wDQrl07XnvtNc4991zefvtt/P39ARg5ciR33HEHAA888AAvv/wyCxcupEOHDkRERADQpEmTE3Z5JScnV0i6HL8nJydXK14RkXLsdtj6IyRvgLTtcGSn+QptBhN+hpBK/qG37kuY+6D5vjAPLjyuW/zgKlj6pvm+w0jY9hMseRkOrIQrP6j8mgCJK2DGVZCfYbZmXPcttBzosq9aa2xFsHWOeR93zIP8zNJ9G78BLBDXD5r3hTWfm98PC/SZAHYbrP4EfrzHTAQHTwY3T+Gh5KYB2LJlCwUFBQwbNuyUzl+3bh3r169nxowZzm2GYWC329mzZw+dOnUCoFu3bs79FouF6Oho59IIIiLkZ0LaTjiyA9J2QE4yNO8HHS6C4Mja+9yf74cV71Xcnr4LvroOxv8PvP1Ktx/ZBT/dV/r7X29CdBfo8Q/z9+JC+P4uMOzQ9e9w5XtmovL9RNj7O7wzBEY8C50vK1+LszMBZv7TrEHxCYKiXPhiDFz/I8R0r5WvftoKss2WmaVvQdaB0u2BTaHDhWaCuP0XSFoLicvMF0B0V7j4FWjex2wFC4qA31+EhCchLx3+9hRY3dc5pOTmJAJ8vNj8pOtXHa/uZ1fruJIlCk5VTk4Ot956K5MmTaqwr0WLFs73Pj4+5fZZLBbsdnuNPis6OtrZheWQkpLi3CciHqAgG/YvM7sk0naYrSRp2yEnpeKxaz6H/1nMf/F3uAg6joKm7Sv/l71hmNfKPFB+u18INOtd+Tl7/yhNbHpcC5GdoWk7s8D1v/8wH8Y//QtGv2qeX1wI39wIhTnQcjC0HAC//Qf+d48ZV/M+ZgtN6ibzAX/hc+a1z7ocorrAzOvg8BbzGglPwsC7zM/dPhdm3wL2ImgzDK54z0ys9v0Bn10BN/wCTdtWfj/tdrNlaOkb5r296iOIaF/tP44K8tIhef2Ju+UwYO8SWPF+aStNUCR0v8b8M2reF6wlz6DzHoLMg2aMicsgrj/0nlCa2FksMOxRCGwMvzxkfo+8dLjkdbcVYiu5OQmLxVKtriF3ateuHQEBASQkJHDTTTfV+PxevXqxefNm2rat4n+8avD19QXM0VAnMmDAAJ555hnnWlEA8+fPJzQ0lM6dO5/y54tILctKMh9u234ya0lsVQwACI42k4um7cA/HHYvhENr4MBy85Xwb2jcBjqOhA6jzKTl4EqzS2TbT5C+u/Lrdr7UfOhby/yjr+gY/HCX+b7XeLjktfLnXPUBzLja7DKJ6QZ9b4KFT5vx+IfDFe9ASCykbjG7Y768Fi5/20x2AEa+AEFl1hls2g5uToA/X4dl70DGPrMFaOEzcCwDMOCsK+Dyd8DbF8b+Fz4ZbdbtfHYZ3DAXwpqXiT8f1s+EP18zkzqHD0fAP782701N2G1msrLgaSjIqv55jdvAoEnQ7Rrw8a/8mLBm0O9m81WVAXdCQGP4/k6zFciw4a40o34/taVa/P39eeCBB7j//vvx9fVl0KBBHD58mE2bNnHjjTee9PwHHniAs88+m4kTJ3LTTTcRFBTE5s2bmT9/Pm+88Ua1YoiMjCQgIIC5c+fSvHlz/P39K51H54ILLqBz585cd911vPDCCyQnJ/PII49w55134ufnV8mVReS05WfBzvmw7WdI2Qxxfc3EotU5FR9mx3ctpW03X4e3lj+uUSszYWhSksg0aWe2TPgf///945B1qCQx+tlMjNJ3mQnCn6+DxavkIVjCy9e8VtlWmsPbYPP38L+7zdYAx75FU81rhcTABU9V/N7t/gbDn4BfHzeLY/PS4Y9XzX2XvlGaaFw+Hd7/m9ki89nl5rYOI81E5Xi+QTD0QRg4CdbOML9Dxj5zX58bYOSLpQmYfxj8czZ8eKF5P98aUP7+5GdBQWbpsX1uLE0GP7kErpkBrYeWHr9/mdmFlnnQ3N5xJMT0NLt/Dq6GH+81u48AwlqAf2jF+MsKamomfB1Glk8aT0ePsRAaYyZm3u77O13JTQPx6KOP4u3tzWOPPcahQ4eIiYnhtttuq9a53bp1Y/HixTz88MMMGTIEwzBo06YNY8aMqfbne3t789prr/Hkk0/y2GOPMWTIEBYtWlThOC8vL3788Uduv/12BgwYQFBQEOPHj+fJJ5+s9meJeIyDqyBlE7S7AEKq2e1amAubvjPrNpq2NxOHkBjzgW4rNh+kjoJZL9/SxCI01jzGbjOPSduBPXUblt0Lsez93ewucUjdBKs+NutC2p5vdr+cqGsJAIvZZdNh5Im7lioTGms+RPveZD7QdyWYQ6t3/GImU/7h0H6Eee22w8xuqLI2/wCzxsOazyAg3KznOLTGTCwALn65kqSqxKC7zULjjV+bLSxgdql0Gl16jF8IjP0C3j3PLJT1C4VRL534+/kGmq0YvSfAtjlmd1fXqyqeE9TULCr+eCRk7K/YohLazGzx6DXOjKNgMnz5DzMJnHE1XPk+WH3MpCzxr9LzDq40a1xCYiC6m1kEjAF+YTD8ceh9vesSlpoqm5C5icWoyXjjBiArK4uwsDAyMzMJDS2f1ebn57Nnzx5atWrlHCEk7qc/F/EohgE7fzUfRnt/N7d5+Zq1DAMnmclIZXLTYPl7sPxdc8RJWb7BZkFuRmL5JKWSY4zMA1gq6zJq0s78l35sT3N+km0/Q/ahSi+VYoSz2x7LLiOGzMB4olt3pXX3gbSOb01YgE+l51SlsNjOHzvTmLMhiV+3pBDk680t57RmTN84/K12OLoPGrUEr5Ncd/Vn8EPJ9BTnPWy25KRshC5XwlUfniSIPPjoQrN7KKIj3LzQTE6Ot+d3s4Vn6ANmN5grFReYiW5ZVi+I6GR2YZVVlA+zb4It/yu/3csXuo0xa152zjcLmAtzSvd3GwMXPF1rxduGYbB6/1HSc8v/N9gsPIDOsSdpJXKBEz2/j6fkpgw9ROsn/blIvZeXbrZ8JK+HFR+aLSMAVm+zhSN1c8mBFrPVo/XQ8v/CT90Ca2aY84WA2eUT0cHsFjq6t3y3jbc/NGlrvooL4MgOjPQ9WMocU2D4sNuIZpcRywZ7a5b59mfKdZfQv3WZ+hHDMLswts8DWyHFjdvywKJj/JISQsvYaGLDA1i8/TCFxeUHDUSG+NE+KoR2UcG0iwyhfVQw7aJCnEnP0dxCtqdksz01h7X7M5i/OZms/Ipzw0SF+nHH0LaM6RuHt9XCvvQ8dqRksyMlhyA/by44K4rmjY5LQP58HeY94vzV5t8Ir7tWmq0jZSRn5jN/czLeXlYu7RFr1k3mpJrFzd3+Xr7upb6y28xuuDWfmS1JfW4gvesN/LLfQnJmPm0ig2nf2Js2uavxSVoD8YOh1ZBaCyc5M58ps9ezcNvhSvc/cGFHbh/aptY+H5TcnJCSG8+jPxepl7bOMedBObwN8tLK7/MNNrsFzr7DLMTc/xf88ZrZfXEisT1h0D1ml4mjS6G4EI7uMbuLwltCWBxYreQX2Vi8/TA/bUhi8ZZDNCk8SKQlg0QjAkKaMaJbc4a0a8pL87az4WAmPl4Wnr6sC2P6tqj0o//9v0189MdewgJ8+OnuITQLDyA7v4gFW1P5aUMS6w9kkpSZX2XokSF+2A2DtJyKrUZNg/24qEs0F3WNZtfhXN5auNN5rVB/b/KL7BTaKo687BEXzqiuMQxo04S/dh/hpw1JnH/oHSZ6fw/ApMI72Rc7kpFdYxjUtinL96QzZ0MSq/YdLfPZvtx6ThuuPbvFSQeHbD6UxfNztzKgTROuO7slQX7ljy+y2Zm9+gDzN6fSq2U44wbEE+xX+TWLbXa8rBYspzPfi2GQsWsF85KD+WFrNkt3H8FmL//I9rJaaNk4kEC/8l1QMWEBPHBhB9pGHtfFVwm73WDupmS+XnWA6DB/RnWNoX+rxnh7WTEMg1mrDvDUj5vJzi/G18tKp9hQHN+qyGZn0yGzq622ExwlNyeg5Mbz6M9F6p0V78Oc+4Ayf32GxJoFtW3ON+swAsIrnnd4u3ludpJzk81ukFbkA92vJaLL+Vi9ys8NUlhsZ09aLttTstmRmmO2bqTmsDctl+IyD7rYMH8u6hrDyK4x9IwLx2o1Hz/HCm3cN2sdczaYn3nj4Fb83wXtyz3o525M5rbPVwHw/rg+DO9c+QR12flF7EjNYWdKTrl4Dh2X9DRvFEC7yGDaR4dwXodI+sY3xsta+pAvKLYxa+UB3lq403lugI8X7aKCaRsRzMGMYyzfm17pSGaLxeChiKV4Y+Opw4OxG5UnD71bNiI1O5/EdLM1zJHkXDegJf6VTLORmVfEqNd/58BR8/jGQb7cPKQ14wa0xNfbyuzVB3h9wU7nfoBGgT7cfE5rZ5JzOLuAuZuS+Wl9Esv2HCEswId2USWtW5EhxIYHUDZaqxW6Nw+nSXDFwtvE9DzeXLiTr1cdKPfn3KVZKJ2iQ9ld8t9EdiWtYg6+3lYm/609Nw1uhbdXxTln7HaDnzcm81rCDralZJfb1yTIlwvOiiYp8xiLSlpruseF8+JV3WgXVT5hevXXHbz863YA7r+wA3cMPfWRtyei5OYElNx4Hv25SL1hGPDbi+ZwYjCHH/e5wewi8guu8eXyi2xc+/4yZ0uDv4+VtpHmgzC/yMb2lGz2Hsmr8K91h9gwf0Z2jWFktxh6NC9NaCqGbfBqwg5e+XWH83PO7xjJyK4xtIsM4arpf5KdX8wt57TmoZGdavw9svOL2Jmag9VioW1kcIUWj6oUFNvYeDCTyBB/moUHlIs/NSufuZuSmbM+iTWJGfRoHs7IrtFc1DWGqFDz74GyycSq/Ufp3jyMkV1juKhLDNFh/hTZ7Hy7+iCvL9zhTHIGtG7CB9f3KZfcGYbBLZ+tYv7mFJqFB+DjZWHvkTzATGCC/LydSU3TYD+u6t2ceZuS2Z1mrr8XHuhD+8gQVu5Lp4o/qipZLTCgTRNGdo3hwrOiySu08caCnXyzujSp6dIslJFdYxjVNYaWTUoXqDQMg9TsAnYdzinXfWgY8MnSvRWSkjYRwRzKPMaOkuT0m9UH2J5i1uyE+Htz3dktSc8t5JdNyRzNK62rOVmSBHWT4Ci5OQElN55Hfy5SL9jtMO9h+Ost8/dzH4ChU055mnm73WDSl2v4cX0Svt5WMKi0awYgxM+btlHBtI8sqXUpaQ2IDvWvUbfHzxuSmPrzVvan51XY16tFODNvHYBPFQ8vT+ZIcp78cTM5BcWc3boxH17f15ngfLBkD0/9uBlfLyvf3D6QTjEhfL/2EK8v2OFMcpoG+3Hbua25tn9LAny9KLbZ+d/6Q7yesNOZ5AB0bx7GqG4x/K1zNLkFxexIzS5JJnJIyykoF5e5v7Qg2Gox51ZzJLPntI/g7mHt6N2yUY2/c2XdSd5eFvIKy89FFuLvzY2DWzFhUCtn3VSRzV7SDZhMQbGNO4a2qVb31msJO5g2v/YSHCU3J6DkxvPoz0Xc5lhGyRDpHeYkb1t/NLdf+DycXb2pFqry4i/beGPhTrytFj69sR/94huXFNXmsDM1G38fr1NOYk7EMAw2Hcrix/VJ/LQhif3peTQK9OHHSWadTUO2at9Rxn+4vFyCsz0lh6un/0mRzeDJS89i3IB45/HFNjvzNqeQV2hjVNcYAnwrdmfZ7Aa/bEomLaeA8zpEEte4klFYJ7D/SB5zNph/FhsOmnPenE5Sc7ykzGNMmb3B2Yrj42WhVdMg2kWF0L15GGP6tqjxCLgTcSQ4rZsG8eOkwS6dBFfJzQkoufE8+nOROlWQA4ufNxdWzD1u7TSLF1z2NnSv/hxQlflqZSL3f70egP9c1Y2r+8Sd1vVOlWEYbE/JoVGgD5GhZ8b/W2UTnP6tGnPg6DEOZhxjZNdo3vxHL5clkaciMT2PIpud1hE17+I8EUdC6+9jpWWToFpvnfts6V4uOCva2X3oKjVJbjSJn4gImIUKW3805znJOli6PSSmdKK8rlebaxHVwLFCG7Yy/4Zcte8oD83eAMBd57d1W2IDZhdIh+iTdzc0JL1bNuLTG/sx7oPlLNtjzifUskkgz13Zza2JDVDjVp/qslgsdGlWxSSHteC6Mq1f7qLkRkQaDsMw536pan2cqhzdCz/db86YC+aQ6wunQvyQk09hfwKvJ+zgpZIahONd0j2WyX87jcUR5ZT1amEmOOM/WE6hzc6b/+hFqL/rumbE/Rpe5ZhUsHfvXiwWC2vXrgVg0aJFWCwWMjIy3BqXiMsUF5gTtL3ZH55rAX9NP8mKyI7zCila9CLFr/eHHb9gs3izJOZ6nm/zMS8ntmNNqo1T7bnPL7Lx/pI9le4b1jGSF65yf0vBmaxXi0b8dv95LPrX0Dpt1ZC6oZabM9DAgQNJSkqqdGHLU7V3715atWrFmjVr6NGjxwmPnTRpEn/88QcbN26kU6dOzqRLpMbyM801kv56u9zcMcx9ABKXmatEH79OkcPeJRz79m4CMs3VmJfaOvNI8QR27WkGe8xrvZqwg2bhAYzsGs3IrjG0P25+D19va5X1CwlbUsk8VkRMmD8J/3cu1jKJTGXzrEjdaxTke/KDxCMpuTkD+fr6Eh1dzUX8askNN9zAsmXLWL9+vVvjkHqqKN9cJLCg/MRiFGSbI5ccK1an7wbHOkohMeaMwBYL/PoEbJptrj30908hsmTulpIVr4uXvYv3hi8JAA4bobzpPQHfvtcw3GpheMlHHTh6jIVbUzmYcYz3ft/De79XbIXx97Ey46azKx3V8vWqRACu6NXMpSNGROTk9H9cA2G323nxxRd59913SUxMJCoqiltvvZWHH364wrGLFi3ivPPO4+jRo4SHhwOwZMkSpkyZwsqVK2natCmXX345U6dOJSjInDAqPj6eW265hZ07dzJr1iwaNWrEI488wi233AJAq1atAOjZsycA5557bqWrggO89tprABw+fFjJTUN3ZJe5TEHqlor7QqLNQt2m7c1J8Ow2s+Zl6xzYtcBcFbs6mnYwV37uenXpAoTN+8Gs681Vrt87H2J7mQlRyYrX3oDdsDDDNoydXe9l8iX9Kx0Om19kY9G2VOZsSCZhS0qFOULyi+y8MHcrM28tX2ScmpXP4u3m0Nsre3nAOkYiDYySm5MxjOr/JetqPoHVniBsypQpvPfee7z88ssMHjyYpKQktm7dWq1zd+3axYUXXsjTTz/Nhx9+yOHDh5k4cSITJ07ko48+ch730ksv8dRTT/HQQw/x9ddfc/vtt3PuuefSoUMHli9fTr9+/fj1118566yz8PVVc+8Z6dhRSNkMO+bBtp/M5OJUhcRC+HHrIHn7mYlQ03alI5jCW1T8/6RFf7j1N/jmRtizGPYtce5KMcLZbG/J5/7/4LqrruC6DlWvoOzv48WFXWK4sEsMNrtBUZlJ9lKzChg+bTHL9qSzdNcRBrQpXZTy2zUHsRvmyBxXD+sVkZNTcnMyRXnwbKx7PvuhQ+AbdNLDsrOzefXVV3njjTcYP348AG3atGHw4MHV+pipU6dy7bXXcs899wDQrl07XnvtNc4991zefvtt59wyI0eO5I477gDggQce4OWXX2bhwoV06NCBiIgIAJo0aeL2Lq8z3q4FkLQe2g6DqC6nPINulWzFkLGvTPfQdkjbaf48fgFJq7c54ih+EHiVSXjtNsg8YJ5zZGdpvUxUV+g4EjqMhJjupxd7cARc9y1s+R87k47wn5U2/shoRA6B/L1Pc16+uHONRsh4WS14WUtrZVo0CWRM3zg++2sfr/y6nQFtzNYbx8ywAFf3VquNiDsouWkAtmzZQkFBAcOGDTul89etW8f69euZMWOGc5thGNjtdvbs2UOnTma9Qrdu3Zz7LRYL0dHRpKamVrieuNGKD2DO/wEG/Pq42arRYSR0uMhsCSnLJwBCm5mr95WVcxi2z4VtP8Ph41r/7MWQdQjsRVQpJNacC6bDSGj3N/CvRuF6fhYU50Nw1a0op6LIsPDs7nZ89IeZxMSE+fPGFV0ZeoLWmpq447w2zFyRWK71Zt2BTHam5uDvY2VktxiXfI6I1IySm5PxCTRbUNz12dUQEHB6U6bn5ORw6623MmnSpAr7WrQo7Rbw8Sn/r1yLxYLdXvlaOFLHDAN+fxEWlCzoGNMdDm+DjP2wbLr5qox3QEk3T1sIaw6Jy80XJxn+XPa8JiV1M03bnfICkuZcMqc+n0xlimx27vpiDXM3JQNwTd84HhrVyaXzmcSEBXBNvzg+XVraeuMoJL7wrGjNnSLiJkpuTsZiqVbXkDu1a9eOgIAAEhISuOmmm2p8fq9evdi8eTNt2576ImeOGhubzXaSI+W02G1gKyo/SZ3dDvMegb/eNH8/519w3sNQdAx2L4StP5k/j68dK8iB4mOQssF8lRXTHTqMMltgrGUe0BYLhMZCaPOKLT71SNnExtfLyuv/6MmIs2qnu/T2oW34crnZerNoWyo/rDX/MXRVb/fNPCxyplNy0wD4+/vzwAMPcP/99+Pr68ugQYM4fPgwmzZt4sYbbzzp+Q888ABnn302EydO5KabbiIoKIjNmzczf/583njjjWrFEBkZSUBAAHPnzqV58+b4+/tXOY/Ozp07ycnJITk5mWPHjjnnuencubMKkStTkGPW0Wz7Cbb/AsfSzeSiaVuzxSTrUOmCjiOmwgCzLgrfQOg4ynxV5vjamaP7IKKD2YUV5rm1IscnNu+M6815LuqGqkzZ1ptJ/11DVn4xsWH+5QqMRaRuKblpIB599FG8vb157LHHOHToEDExMdx2W/VWLe7WrRuLFy/m4YcfZsiQIRiGQZs2bRgzpvqLA3p7e/Paa6/x5JNP8thjjzFkyJAqh4LfdNNNLF682Pm7Y/j4nj17iI+Pr/ZnNkh56eULdVM2wZ7fwVZQ/risA+Zr9yLzd4sXXPYWdL+m+p/l5Q1N2pgvLnTVN3CrIpudiV+s5pdNKfh6W3nnutpNbBwcrTdZ+cUAXNGrOV5WzT4s4i5aFbwMrT5dP50Rfy6ZB2D2LbDvj8r3N4o3u4k6XAQRHSF9V2kSlJNqJjWth9ZlxPXSA1+vZ+bKRHy9rbx7XW+XFQ5Xx+Pfb+STpfsAWHjfUFo1rd/d2SKeRquCi3iSnQnwzU1mdxOYI5ick9u1g/jB5gy7ZYdFB0dAi7PdE289tWz3EWauTMRigXfqOLEBuOO8tizYlkqvFo2U2Ii4mZIbEXex2+G3F2DRc4BhFvFe/Qk0buXuyDxOkc3OY99vAuAf/VrUSVfU8aJC/fn9/vPr/HNFpCIlNyLukJ0M390BuxLM33tfDxc+X34UlFTbJ3/uZVtKNo0CffjXiA7uDkdE3EzJjUhdstvMifYWPAUFWeZ8MRe/DD3Gujsyj5WSlc8rv+4A4MGLOhIeqBF3Imc6JTeVOMNqrOu9BvPncXA1/HgvJK01f4/tBZe+AVFnuTUsT/fsT1vIKSimR1w4V2tuGRFByU05jhl48/LyTnvWX3GdvDxz8rnjZ0j2GPmZ5szBy98DDPALg2GPQp8boMxaRVJzf+0+wvdrD2GxwNOXdcGq4dcigpKbcry8vAgPD3eulxQYGIjF1YsOSrUZhkFeXh6pqamEh4fj5eVhiYBhwMZv4JeHICfF3Nb173DB0xAS5d7YGgCziHgjAP/s35IuzaqxhpWInBGU3BzHsaK1FoSsP8LDwz1vpfEju2DO5NJJ9pq0hVEvaS4aFzEMg0e/28j2lBwaB/ly3wUqIhaRUkpujmOxWIiJiSEyMpKiohOsfCx1wsfHp9632KTnFlJssxMZ6g9F+bDkZVgyDWyF4OUH59wHg+4Gbz93h9pgvPPbbr5ckYjVAv+5qhthgR7aZSkitULJTRW8vLzq/UNV3C8rv4iRr/5OWk4B/z0/j76bn4H03ebONsNg5H9KljcQV/lpQxLP/bwVgMcu7sywTuriE5HylNyInIZ3Fu/ClpXENJ/P6btkqbkxOBounApnXV5+VmE5bav3H+XemWsBuH5gPNcP0oSHIlKRkhuRU3R43xaa//EIv/stxt9ShM2w8Kl9BM2HPc3furRzd3gNTmJ6Hjd/spKCYjvDO0Xy6MWd3R2SiNRTSm5EaurgKvjjVZps/oGxVnMOHqN5P172vok3tgbjPWsHr3sHc1HXGDcHWj/lF9n4ZvUBBrRuQuuI4GqdU2Szc9vnqziSW8hZsaG8ek1PrbotIlVSciNSE+u/gtk3A2AFFth60Hz0FNr3HcG9BhyctY5v1xxk4n/X8L6PF+d1rPs1jurSzBX7+W17Gg+N6kSz8JPPDZWSlc/Nn65k/YFMYsL8WXjfUPx9Tl7b9tbCXWw6lEV4oA8fjO9LkJ/+6hKRqlndHYCIxyjMhXmPArAqcDAjCp5jVodptO93IVgseFktvHh1dy7v2Qyb3eCR7zaSX2Rzc9C1p6DYxlM/bmHOhiQufeMPVu07esLj1x/I4JI3lrD+QCYASZn5fPzn3pN+zuZDWby+wFxe4d+XnEV0mNbfEpETU3IjUl1/vQU5yeQHNWds+s3ssrSssEijl9XC1Cu6EhPmz8GMY3y2dJ+bgq19f+46Qk5BMQBpOQWMffcvZq8+UOmxP64/xN/fWUpKVgHtIoOZ/Lf2ALy5cCdHcwur/Iwim537Zq2j2G4w4qwoLuke6/ovIiINjtp2Raoj9wgseRWANyxjKcSHcf1bVFoz4u/jxeS/tedfX6/n9QU7uLpP81pbzHFHSjZPz9lCsL837SNDaB8VTLuoYOKbBOHtVbv/dpm3KRmAK3o2I6egmHmbU5j81Tq2p+RwaY9YtqdksyMlhy1JWSRsNSfFPK9DBK+N7Umgrzc/b0xmS1IWbyzcWWVx8FsLd7E5KYtGgT48fVlXzRguItWi5EakOn77DxRmkxTQnjfTuhPk68WkYVWPiLqiV3M+WLKHrcnZvLVoFw+N7OTykLanZPOP9/4iLcds+ZhDknNf02BfHht9FqO7xdRKQmCzG8zfbC4pcVnPZgxu25QX523jrUW7mL7YfB3vpsGtmDKyk7MQeMpFHRn34XI+XbqX6wfGE9c4sNzx5bqjLu1CRIgmQRSR6lG3lMjJpO/BvuJ9AP6VeSUGVu79W3uaBlf9sPWyWnjwoo4AfPzHXhLT81wa0vaUbMa+ayY2Z8WGMuWijlzZqzndm4cR6OtFWk4hk/67hts/X83h7IJy52YeK2L26gN8sGQPe9JyT+nzV+8/SlpOISH+3pzduglWq4X7L+zIy2O6Ex7oQ4i/N71bNmJsvzgeu7gz394xkEcu7lxuhNM57SMY3LYpRTaDF+dtK3f9IzkFzu6oC8+KZnQ3jTwTkepTy400OIZh8PzcbeQVFvPoxZ3xOY3umfwiG7tm3M9Z9iJ+s3VlW1Af3ru8K3/rfPJZcc9tH8HANk34c9cRps3fzstjepxyHGVtSzZbbBzDomfc1L9ct1eRzc6bC3fyxoKdzN2UzLI9R3j04s4YBszZkMTvOw5TZDOHsD/142Y6xYQyqms0I7vGVHto9i8bzS6pYR0j8fUuvb+X92zOpd2bYbFQrRajBy/qyMWvL+H7tYe4aXBrYsP9ee/3PXy6dC95hTYaBfrw1GVd1B0lIjXi9pabN998k/j4ePz9/enfvz/Lly+v8tiioiKefPJJ2rRpg7+/P927d2fu3Ll1GK14ggVbU5m+eBefLt3HY99vxDCMU7pOWk4B9732KWcdmQfA8raTmH/vOdVKbMB8uE+5yOyO+m7tQTYezDylOMo6WWID4ONl5Z7h7flh4mA6x4RyNK+IyV+t4/9mrWPB1lSKbAbtIoMZ3LYpXlYLW5KyeHHeds5/aTHvVNKddDzDMPhls5ncjDir4oKmVqul2slIl2ZhXN6zGQB3frGaIS8sZPriXeQV2ujaLIwPru+r7igRqTG3ttzMnDmTyZMnM336dPr3788rr7zCiBEj2LZtG5GRFecHeeSRR/j8889577336NixI7/88guXX345f/75Jz179nTDN5D6pthmd647BPDf5YnENwni1nNrtr7TkdSDfPLRO9yZOxuskNRiNPeN/3uN4+naPIxLe8Ty/dpDPPr9Rm47tw3tIoNp2SSoxpPQ5RYUM+Gj5SdMbMrqHBvK9xMH8dbCXXywZDfRYf6M7BrDqK4xtIsKAeBobiHzNifzw7pD/LHzCG8t2sX1g+Lx86567pktSdkkph/Dz9vKuR0iavQdKvN/F7Rnzvok9pd03XVtFsY9w9txfsdItdiIyCmxGKf6z1oX6N+/P3379uWNN94AwG63ExcXx1133cWDDz5Y4fjY2Fgefvhh7rzzTue2K6+8koCAAD7//PNqfWZWVhZhYWFkZmYSGhrqmi8i9caXy/fz4OwNhAf6cOOgVrw0fzsAb13bi5EnmzG46Bis+ICiTd/jdXAFVsz/New+QVjv+BMaxZ9STInpeQx7aTGFNrtzm6+3lXaRwTw8shMD2zat1nWe+3kr0xfvoll4AHMmDXbpCCyb3WDgcwmkZBXw7nW9uaCSFhmHl+dv59WEHQzvFMX74/u45PO/WpnIvE3JjO3XQkmNiFSqJs9vt3VLFRYWsmrVKoYPH14ajNXK8OHDWbp0aaXnFBQU4O9ffgKvgIAAlixZUuXnFBQUkJWVVe4lDVNeYTEv/2omM3ed3467hrXj+oHxANw7cy1r9p9gkjm7HWZNgHkP43NwOVYMtlpakd73/7DevuSUExuAuMaBfHpjP67o2YwuzULx97FSWGxn06Es7vhiNanZ+Se9xs7UHD5YYq42/sQlZ7l8aLmX1cLobuYcMt+vO3TCY3/Z5OiSct1q3H/vE8f74/syrFOUEhsROW1u65ZKS0vDZrMRFVX+L8ioqCi2bt1a6TkjRoxg2rRpnHPOObRp04aEhARmz56NzVb1LLBTp07l3//+t0tjl/rpwyV7SMkqoHmjAP55dgsAHr24M4npeSRsTeXmT1dyVe+4ShfqHpI4nYEHf6YQH54tGsuqwEG8dutoGjcNcklsZ7duwtmtmwBgtxscOHqM22esYtOhLB75diPvXNe7yoe6YRg88cMmimwG53eMZHin2lnS4bKezXh/yR5+3ZxCdn4RIf4+FY7ZfySPrcnZeFktDO/kuuRGRMSV3F5QXBOvvvoq7dq1o2PHjvj6+jJx4kQmTJiA1Vr115gyZQqZmZnOV2JiYh1GLHUlLaeA6YvNlo1/jejgrBnxslp4bWxPOseEkpZTyPTFu3h7UfnX3t++YODBjwB4sPBGfg66lNduHU0rFyU2x7NaLbRoEsiLV3fHx8vCvM0p/HCC1pKfNiSzZGcavt5WHh/dudZaNs6KDaV1RBAFxXbmbUqp9BhHq02/+MY0CqqdiQlFRE6X21pumjZtipeXFykp5f8STUlJITq68v7+iIgIvvvuO/Lz8zly5AixsbE8+OCDtG7dusrP8fPzw89Poy08ld1usC0lmzYRweWGHB/v9YQd5BQU07VZmLN7xSHIz5vPbuzH53/tJyu/qNy+yLydTNj6DthhadRYYlvfwDf94mjeqPyEcrWhU0wod53fjmnzt/P4D5sY0KYJkSHlu11zC4p56sfNANx+bhtaNqmdhAvM0V2X9WjGtPnb+W7tQa7s3bzCMbXRJSUi4mpuS258fX3p3bs3CQkJXHbZZYBZUJyQkMDEiRNPeK6/vz/NmjWjqKiIb775hr//veajWMQzfLBkD8/8tIVm4QHccV4bru4dVy7JsdkNft9xmBnL9gMwZWRHrJWMQmoS7Mfdw4+bUTj3CLw3Buz50Po8Blz7BgO86vZ/iduHtuGXTclsOpTFw99u5N3juqdeW7CD5Kx84hoHcPvQmo34OhWXdI9l2vzt/LEzjdTs/HLJ1uHsAlaV1C2dqOBYRMTd3DoUfPLkyYwfP54+ffrQr18/XnnlFXJzc5kwYQIA48aNo1mzZkydOhWAZcuWcfDgQXr06MHBgwd54oknsNvt3H///e78GlKLvilZiPFgxjEe/nYjby3cxR3ntaFV0yB+3pDMzxuTScsxZ+Ad2iGCgW2qMfLoyC7Y9hOsmQEZ+6FRK7jqQ6jjxAbMOWlevLo7l7yxhPmbU/h82X5aNg50rsvk+P5PjD4Lf5+qh2e7SnzTILrHhbMuMYM565OYMKgVYLagPfG/TRgGdG8eRmx4QK3HIiJyqtya3IwZM4bDhw/z2GOPkZycTI8ePZg7d66zyHj//v3l6mny8/N55JFH2L17N8HBwYwcOZLPPvuM8PBwN30DqU0HjprFq1YL3DeiAx//sdeZ5JQVFuDDiLOiuP/CjpVfyG6Hgyth6xzY9jOklZnq3y8Mxv4XAhvX4jc5sbLdU49+t7HC/hFnRTGsDot3L+sRy7rEDL5be8iZ3Lw4bxtz1ifh42VhSi2skyUi4kpunefGHTTPjef4dOleHvt+E33jGzHrtoHkF9n47/L9vPvbbvIKbVzQOYpR3WIY2KZpxXqconzYvQi2zYFtcyE3tXSf1RviB0OHUdD5EghxfxdLkc3Ote8vY9W+o8Q3CaR9VAjtIoPpEB3KBWdFndYSEjWVmp3P2c8mYDdg0X1DWbbnCA98swGAl67uXmktjohIbavJ81trS0m99esWMyFxtFr4+3gxYVArJgxqhWEYVY8aOrwdPr8SMveXbvMLhbbDoeMo82dAeC1HXzM+XlZm3nI2NruBdx0mMpWJDPFnUNum/L4jjX//bxO/70gDYNKwdkpsRMQjKLmReim3oJi/dh0BqHRelyoTm4Or4POr4Fg6BEdB50uhw0XQcjB41++hyxaLBW+v+jGB3aU9mvH7jjQWbjtc8nss9x5fkC0iUk8puZF66fcdaRTa7LRsEkibaq5Uze5F8OW1UJgDsb3g2q8hqEmtxtlQjTgrioe/tVJQbKdvfCNeuKqbZg4WEY+h5EbqpYQt5vxHwzpWczr+zT/ANzeCrRBanQvXzAC/kFqOsuEK8ffhoZGdWLbnCM9c1vWEC2mKiNQ3Sm6k3rHbDRZuM+ttTrrUQFE+LJkGv/0HDDt0Gg1XfgDemrjxdI0fGM/4krW5REQ8iZIbqXfWHsggLaeQEH9v+rY6wRDtnQnw032Qbi67QK9xcPErYFUrg4jImUzJjdQ7ji6pc9tHVD4EOjsZ5k6BTbPN30Ni4MKp0PkyKl0VU0REzihKbqTeSdji6JKqZOK6A6tgRsloKIsV+t8GQ6eAv+YsEhERk5IbqVccsxJ7WS0M7RBRfueuheZoqKJciO4Kl74JMd3dE6iIiNRbSm6kXnG02vRu2YjwwDLz0mz+Hr65yRwN1XoojJkBftUcIi4iImcU906FKnKcX51DwMuMklr1Mcy63kxsOl8K//hKiY2IiFRJyY3UG8cKbSzbnQ6ULLlgGLDkZfjf3eYw717j4aqPNMxbREROSN1SUm9sT8mm0GanSZAvbZoGwrxHYOkb5s7B98KwxzUaSkRETkrJjdSd7BSwF0NYs0p3b0nKAuCs6CAsP0yEtTPMHRc8DQPvqqsoRUTEwym5kdp3cBX88Rps+cHsXorqai5m2XEkxPRwtsZsScrCj0Iezp0KB38Dixdc8jr0vNa98YuIiEexGIZhuDuIupSVlUVYWBiZmZmEhmpulFpjGOYMwn+8Ant/L91usZoJjkNQBPiHAXAo4xjexblEWjLAyw+u/gg6jqrTsEVEpH6qyfNbLTfieoYBP95jjnICsHpDl6tg0CQIjoYdv8C2n2DnAsg9bL6AWAAL2HxC8Lr2S4gf7KYvICIinkzJjZwau63qNZx+fdxMbBwzCJ99B4THle7v8Q/zVZQPyRvAXsThnALu+Hw1XlYLn/7feLxCmtTJ1xARkYZHyY3U3J9vQMK/ofs1MPzfEFhmccslL8Mfr5rvR79qLmZZFR9/iOsLwLrNKaww8ugYEYKvEhsRETkNmudGaiZlE/z6hDmh3upP4Y0+sGaG2RW16mNzH8DfnjxxYnMcx0ipTjGqgxIRkdOjlhupPlsxfD8R7EXQcrC5eGXqZvj+Dlj+DiStN48bfC8MurtGl96anA1Ax+gQV0ctIiJnGLXcSPUtexsOrQa/MLjyfbj1N7OFxicQktYBBvS+3pxsr4bUciMiIq6ilhupniO7YMHT5vsRT0NojPl+0N1w1hWw6Dmz9mb4EzWeRfhYoY09R3IBJTciInL6lNxIeZkHYMMsaN4X4s4GL2+w2+GHSVCcD63OhZ7XlT8nPA4ue/OUP3JbSjaGAU2DfYkI0bpRIiJyepTcSKljGfDJJZC+y/w9oBG0G2H+3LfE7H665DWXr++kLikREXElJTdistvgmxvNxCawiTmL8LGjsP7L0mOGPQaN4l3+0VtLkhsVE4uIiCsouRFTwr9h56/gHQD/nA1RXSDxL9j2M+yYD5Edod8ttfLRW5LMkVJquREREVdQciOwflbpxHuXvgGxPcz38YPN14hnau2jDcNgS7K6pURExHU0FPxMd2gN/DDRfD/4Xuh6VZ1+/MGMY2TnF+PjZaFNRHCdfraIiDRMSm7OZLlH4MtrzVFQ7UbA+Y/WeQhbS7qk2kQE4+ut/xxFROT06WlypjIMs8Um6yA0aQtXvlf1Qpi1SCOlRETE1ZTcnKlWvA/bfgIvX7jqI/APc0sYpfU2GiklIiKuoeTmTJSyGeY9Yr4f/m+I6ea2UBzdUh2j1XIjIiKuoeTmTFN0zJzPpjgf2v4Nzr7dbaHkFRZr2QUREXE5JTdnmnmPmit5B0XCZW+5fLbhmtieklOy7IKfll0QERGXUXJzJtn+C6x4z3x/+dsQHOnWcEqLiVVvIyIirqPk5kzy23/Mn2ffAW2HuzcWYNG2VAA6q0tKRERcSMnNmeLILjiwAixWGHS3u6NhS1IWv2xKwWKBK3o1d3c4IiLSgCi58VSZB82FLatr/Vfmz9bnQUh07cRUA68l7ABgZNcYOmjBTBERcSElN54oOwXe7AefXla94w0D1s8033cbU2thVdeWpCx+3piMxQJ3D2vn7nBERKSBUXLjiQ4sh8IcSFoL2cnVOH4FHN0DPkHQ6eJaD+9kHK02o7rG0D5KrTYiIuJaSm48UfKG0vcHV5/8eEerTaeLwTeodmKqprKtNpPUaiMiIrVAyY0nKpfcrDrxscWFsHG2+b4edEmp1UZERGqbkhtPlLyx9P2hk7Tc7PwVjqVDcBS0HlqrYZ2Mam1ERKQuKLnxNMeOQub+0t8PrjILhqvi6JLqerVbVv0uy9Fqc3G3WNqp1UZERGqJkhtPk7LJ/BkSC97+kJ8J6bsrP/ZYBmz72Xzv5i6ptJwCft5oFj9POr+tW2MREZGGTcmNp3HU28T2hOiu5vuqioq3/AC2AojoVHqsm6xLzACgXWSwWm1ERKRWKbnxNI56m+iu0Ky3+b6qouJ1JV1S3ce4dYFMgHUHMgHo1jzcrXGIiEjD5+3uAKSGktebP6O7QNEx831lyU1GIuxbAljMehs3W38gA4DucWHuDURERBo8JTeexFYEh7ea76O7gq3YfJ+83tzn5VN67IaS5RbiB0OYe9duMgyD9Wq5ERGROqJuKU+Sth1sheAXCuEtoXFr8A+D4nxI3Vx6nGGUdknVg7ltDhw9RnpuIT5eFjrFqN5GRERql5IbT+IoJo7qYtbQWK0Q28vcVrZrKmkdpG0zR1N1vqTu4zyOo9WmY3Qoft7uHY4uIiINn5IbT+JIbqK7lG5r5khuyoyYcsxt0+Eis2XHzRz1Nt2auz8WERFp+JTceBJnclNmWLdzxFRJcmMrhg1fm++7XVN3sZ3AOkcxseptRESkDqig2FMYxomTm8NboDAX9i2F3FQIaAxth9V9nMex2w02HswCoJtGSomISB1Qy42nyE4y14iyeJmT8jmERJuzFRt2s9bG0SXV5cryo6fcZHdaDjkFxQT4eNE2Itjd4YiIyBlAyY2ncLTaNG0PPv7l9znqbvb8Blt/NN93ryddUolmMXGXZqF4e+k/NxERqX162niKyoqJHRxdU0vfhKI8aNymdJublRYTh7s1DhEROXO4Pbl58803iY+Px9/fn/79+7N8+fITHv/KK6/QoUMHAgICiIuL49577yU/P7+OonWjyuptHBwtNwVmbQvd3L/cgkPpsguqtxERkbrh1uRm5syZTJ48mccff5zVq1fTvXt3RowYQWpqaqXHf/HFFzz44IM8/vjjbNmyhQ8++ICZM2fy0EMP1XHkbnCi5Ca2Z/nfu7l/uQWAwmI7m5PMhEsjpUREpK64NbmZNm0aN998MxMmTKBz585Mnz6dwMBAPvzww0qP//PPPxk0aBD/+Mc/iI+P54ILLmDs2LEnbe3xeAU5kL7bfB9VSXLjH2bW4gDE9TdnLq4HtiVnU1hsJyzAh5ZNAt0djoiInCHcltwUFhayatUqhg8fXhqM1crw4cNZunRppecMHDiQVatWOZOZ3bt389NPPzFy5Mg6idltUjcDBgRHQ3BE5ce0LbmPvSfUWVgns67M5H2WetJNJiIiDZ/b5rlJS0vDZrMRFRVVbntUVBRbt26t9Jx//OMfpKWlMXjwYAzDoLi4mNtuu+2E3VIFBQUUFBQ4f8/KynLNF6hLJyomdhj2GHQfCzHd6iamatDMxCIi4g5uLyiuiUWLFvHss8/y1ltvsXr1ambPns2cOXN46qmnqjxn6tSphIWFOV9xcXF1GLGLnKjexsEnoF4lNoBWAhcREbdwW8tN06ZN8fLyIiUlpdz2lJQUoqOjKz3n0Ucf5brrruOmm24CoGvXruTm5nLLLbfw8MMPY7VWzNWmTJnC5MmTnb9nZWV5XoKTtsP8WXbyvnour7CY7SnZAPSIC3dvMCIickZxW8uNr68vvXv3JiEhwbnNbreTkJDAgAEDKj0nLy+vQgLj5WWuMm0YRqXn+Pn5ERoaWu7lcY7uNX82buXWMGpi06Es7AZEhfoRFep/8hNERERcxK1rS02ePJnx48fTp08f+vXrxyuvvEJubi4TJphFsePGjaNZs2ZMnToVgNGjRzNt2jR69uxJ//792blzJ48++iijR492JjkNTnEBZB003zfynORmXWIGoC4pERGpe25NbsaMGcPhw4d57LHHSE5OpkePHsydO9dZZLx///5yLTWPPPIIFouFRx55hIMHDxIREcHo0aN55pln3PUVat/RfYABPkEQ1NTd0VTbX7vTAXVJiYhI3bMYVfXnNFBZWVmEhYWRmZnpGV1U2+fBF1dDVBe4/Q93R1Mt+UU2ej45n2NFNuZMGsxZsRotJSIip6cmz2+PGi11Rjq6x/zZKN6tYdTE0l1HOFZkIzbMn84xHpBAiohIg6Lkpr5LL0luPKiY+Nct5gi48ztFavI+ERGpc0pu6jvHSCkPabkxDIMFW821wYZ1ijrJ0SIiIq6n5Ka+c3ZLeUbLzaZDWSRl5hPo68WA1k3cHY6IiJyBlNzUZ3a7x81xk7DFbLUZ3LYp/j4NdHi+iIjUa0pu6rOcFCjOB4sXhHnGrMoJW816m+HqkhIRETdRclOfObqkwpqDl497Y6mGlKx853pSQztWsXq5iIhILVNyU5952EgpRyFx97hwIkO05IKIiLiHkpv6zMPmuEkoGQI+vGOkmyMREZEzmZKb+sw5DLz+t9zkF9lYsjMN0BBwERFxLyU39ZkHdUv9sTON/CI7sWH+dIoJcXc4IiJyBlNyU595ULfUr1tKJ+7TrMQiIuJOSm7qq/wsyDtivq/n3VLmrMRmvc2wTqq3ERER91JyU1856m0Cm4B//V58MjH9GClZBfh6WzlbsxKLiIibKbmprzyoS2p3Wg4ArZoEaVZiERFxOyU39ZUHjZTafTgXgNYRQW6ORERERMlN/eVBI6X2pJnJTaumSm5ERMT9lNzUV57YLaXkRkRE6gElN/WVo+XGA7ql9ji7pYLdHImIiIiSm/rJVgSZB8z39bxbKq+wmEOZ+QC0VsuNiIjUA0pu6qPMRDBs4OUHwdHujuaE9qblAdAo0IdGQb5ujkZERETJTf2UXqbexlq//4hUbyMiIvVN/X5yNkBHcwvJKyw+yUF7zZ/1vEsKVG8jIiL1j5KbOpSalc/g5xdwy6erTnygR42U0jBwERGpX5Tc1KH1BzLJLbTxx640svKLqj7Qg0ZKOZIbFROLiEh9oeSmDu1PN4tvDQPWJ2ZWfeDRfebPet4tZRgGuw+bNTfqlhIRkfpCyU0dSjya53y/NvFo5QcZhsd0Sx3JLSQ7vxiLBVo2CXR3OCIiIoCSmzqVmH7M+X5tYkblB+WmQWEOYIHwlnUS16lyrCnVLDxAC2aKiEi9oeSmDiWml225ycAwjIoHHdlp/gxtBj7+dRTZqdmjYeAiIlIP1Ti5+eijj5g1a1aF7bNmzeKTTz5xSVANkWEY5bql0nIKOXD0WMUDD28xf0Z2rKPITp2j5aaN6m1ERKQeqXFyM3XqVJo2bVphe2RkJM8++6xLgmqIjuQWkldow2KBjtEhQBVdU6mO5KZT3QV3ijQMXERE6qMaJzf79++nVauKo3hatmzJ/v37XRJUQ+TokooO9advfGPgZMlN5zqK7NSVjpRSciMiIvVHjZObyMhI1q9fX2H7unXraNKkiUuCaogcw8DjGgfSIy4cqCq52Wz+jKjf3VLFNrvzO6nlRkRE6pMaJzdjx45l0qRJLFy4EJvNhs1mY8GCBdx9991cc801tRFjg+Cor4lrFEiPFuEAbDyYSZHNXnpQzmHIOwJYIKJD3QdZAwczjlFkM/DzthIbFuDucERERJy8a3rCU089xd69exk2bBje3ubpdrudcePGqebmBBKdLTcBtGoSRKi/N1n5xWxNyqZr8zDzIEerTaN48K3frSGOYuJWTYOwWi1ujkZERKRUjZMbX19fZs6cydNPP83atWsJCAiga9eutGxZv+dkcTdHF06LxoFYrRa6x4Xz+4401iYeLZPceFC9jYqJRUSknqpxcuPQrl072rVr58pYGjTHMPC4xuZMvj1Lkps1iRlcN6DkIEfLjSeMlFIxsYiI1FM1rrm58soref755ytsf+GFF7j66qtdElRDU2yzcygjHzBbbgBn3U25ouLDW82fHpDc7HG23GiOGxERqV9qnNz89ttvjBw5ssL2iy66iN9++80lQTU0SZn52OwGvt5WIoL9AOjePBwwa1cy84rMNaU8aY6bkpobtdyIiEh9U+PkJicnB19f3wrbfXx8yMrKcklQDY1zGHijAGfxbZNgP2crzroDGZB1EAqywOoNTep3d19uQTHJWWZLVGvV3IiISD1T4+Sma9euzJw5s8L2L7/8ks6d638hrDskppevt3FwzHezLjGjtNWmSVvwrpg81ieOLqnGQb6EB9bvWEVE5MxT44LiRx99lCuuuIJdu3Zx/vnnA5CQkMAXX3zB119/7fIAGwJnMXGjisnND+sOmXU3/p5TTLxHI6VERKQeq3FyM3r0aL777jueffZZvv76awICAujevTsLFiygcePGtRGjx9ufbk7g1+L4lpsyRcVG2BYs4BHDwHekajVwERGpv05pKPioUaMYNWoUAFlZWfz3v//lvvvuY9WqVdhsNpcG2BCUncCvrM4xofh4WTiSW0hR0iZ8od4vu7B01xHe/W0XAF2bhbk5GhERkYpqXHPj8NtvvzF+/HhiY2N56aWXOP/88/nrr79cGVuDUVXNjb+PF51jQrFix3pku7mxHrfc/LkrjQkfLye/yM7QDhGM6Rvn7pBEREQqqFHLTXJyMh9//DEffPABWVlZ/P3vf6egoIDvvvtOxcRVyC0o5khuIVAxuQHo16oxGQe34W3LBy8/aFxxxfWNBzP57/L9PHBRR0L9fWo95sr8uSuNGz5e4Uxspv+zN/4+Xm6JRURE5ESq3XIzevRoOnTowPr163nllVc4dOgQr7/+em3G1iA4ionDA30qTUyGtIuggyURACOiA1grJgyPfb+RGcv28+3qg7UbbBWU2IiIiCepdsvNzz//zKRJk7j99tu17EINJKaXrgZemX6tGrPS6xAA2aHtCD1uf1pOAWtKZjF2zC1Tl/IKi7n1s1VKbERExGNUu+VmyZIlZGdn07t3b/r3788bb7xBWlpabcbWIFRVTOzg7+PFgJAUALbbm1fYv3BrKoZhvk/NKqidIE/g4NFjZOcXE+LnrcRGREQ8QrWTm7PPPpv33nuPpKQkbr31Vr788ktiY2Ox2+3Mnz+f7Ozs2ozTY+2vopi4rA6WAwAsyYqosC9hS6rzfWp23bfcHM0rAqBpiJ8SGxER8Qg1Hi0VFBTEDTfcwJIlS9iwYQP/93//x3PPPUdkZCSXXHJJbcTo0Q5UMYGfU3EhjY7tBeB/SeEUFJcOpS8otvH7jsPO3w9n133LTXpJMXR4oHsKmUVERGrqlIeCA3To0IEXXniBAwcO8N///tdVMTUojpab4yfwc0rfhcVeTC7+7CpqxOp9Gc5df+1OJ7fQhlfJelSpbkhuMvLM5KaxllkQEREPcVrJjYOXlxeXXXYZP/zwgysu12AYhlFaUFxVclOyptThgNaApVxLTcIWsxZnWMdIwGxFKbLZay/gSji6pbSGlIiIeAqXJDdSubScQo4V2bBYoFl45QXFzgUzI8w1pX7fYRZpG4bhrLe5qndzvEtab9Jy6rb1xtFy00jdUiIi4iGU3NQixxw3MaH++HpXcauT1gLQpHV3ADYeyiQ9t5BtKdkczDiGn7eVIe0iaBrsB9T9iClHzU2jILXciIiIZ1ByU4uqWnbBqSAbdi8GIKTTcDpGh2AY8MfONGerzaC2TQnw9SIytCS5qeO6G0e3VCN1S4mIiIdQclOLTprcbP8FbAXQpC1Eduac9uZQ8N93HOZXR71NJ7PeJjLEkdzU7XBwdUuJiIinUXJTi042OzFbSgqwO10CFgtD2jUFYP7mFNaWzEo8rGMUABEh/kDdd0sdzXMMBVfLjYiIeIYaLZwpNZNS0soSE+5fcWdhHuyYb77vbM4P1De+MX7eVmdXUJdmoUSHmec6Wm4O13FBsbNbKkgtNyIi4hnqRcvNm2++SXx8PP7+/vTv35/ly5dXeezQoUOxWCwVXqNGjarDiKsnv8ickC/Qt5KZfXf+CkV5EN4CYnoA5lIM/Vo1dh7iaLUBiAip+4Jiu93QPDciIuJx3J7czJw5k8mTJ/P444+zevVqunfvzogRI0hNTa30+NmzZ5OUlOR8bdy4ES8vL66++uo6jvzkCorNOWn8vCtJbo7rknI4p13pEgzDO5UmN86WmzqsucnOL8Zesq6VuqVERMRTuD25mTZtGjfffDMTJkygc+fOTJ8+ncDAQD788MNKj2/cuDHR0dHO1/z58wkMDKyXyU1hSXJTYRh4cYFZTAxmclPGeR0j8bJaaNkkkC7NStcIjwwtqbmpw9FSjnqbIF+vqoeyi4iI1DNurbkpLCxk1apVTJkyxbnNarUyfPhwli5dWq1rfPDBB1xzzTUEBQVVur+goICCgtKEICsr6/SCroHSlpvjEoPdi6AgC0JioHnfcrvaRgbz7R0DaRzki6VMi05py00BdruB1WqhtqmYWEREPJFb/zmelpaGzWYjKiqq3PaoqCiSk5NPev7y5cvZuHEjN910U5XHTJ06lbCwMOcrLi7utOOuLscimBWSm82OLqnRYK34R9CteTjNjxth5ZjEr9hukHGsyPXBVsKR3KiYWEREPIlH9zV88MEHdO3alX79+lV5zJQpU8jMzHS+EhMT6yy+gqJKam5sRbD1R/N9p+qvou7rbXXONVNXc90czdUEfiIi4nncmtw0bdoULy8vUlJSym1PSUkhOjr6hOfm5uby5ZdfcuONN57wOD8/P0JDQ8u96kpBZTU3e3+H/AwIbAotB9boepF1PNeNs+VGyY2IiHgQtyY3vr6+9O7dm4SEBOc2u91OQkICAwYMOOG5s2bNoqCggH/+85+1HeYpK6ys5sbRJdVxFFgrGUV1AnW9BEOGc+kFdUuJiIjncPskfpMnT2b8+PH06dOHfv368corr5Cbm8uECRMAGDduHM2aNWPq1Knlzvvggw+47LLLaNKkiTvCPinDMEprbnxKkhu7rbRLqnP1u6QcIup4CYZ0FRSLiIgHcntyM2bMGA4fPsxjjz1GcnIyPXr0YO7cuc4i4/3792M9ruh227ZtLFmyhHnz5rkj5GopthvOOWKcNTcpGyH3MPiFQfw5Nb6mo1vqcJ213JRM4KcVwUVExIO4PbkBmDhxIhMnTqx036JFiyps69ChA4Zh1HJUp8dRbwNluqUySoqZm7QB75onDKUtN3VUc1NSUByubikREfEgHj1aqj4rLJPc+HqV3ObsJPNnaOwpXdM5140KikVERKqk5KaWOOptfL2spRPuZR00f55mclNXNTelBcVKbkRExHMouaklpXPclLnFWSUtNyExp3TNulyCwTAMZ0GxJvETERFPouSmljiXXvApc4uzD5k/Q5ud0jUdLTd5hTZyCopPK76TOVZkc3atqeVGREQ8iZKbWuJcNNOrkpab0FNruQny8ybQ1xx5Vdsjpo6WdEn5elmdnykiIuIJlNzUktI5bkoSA8OArJKWm5BTq7mBMnU3WbVbd3M01zHHjU+5BTxFRETqOyU3taTCiuAFWVCUa74/xZYbKLMEQ6233GiklIiIeCYlN7Wkworgji4p/zDwDTrl60bU0RIMjm4pFROLiIinUXJTSxyjpZyLZjqGgZ9GlxTU3XDwDLXciIiIh1JyU0sKbY5uqZKam+zTKyZ2cMxSXOsFxc7ZiZXciIiIZ1FyU0sqzHOTdXqzEzvU1fpSpTU36pYSERHPouSmllRYETz79EdKQdnRUnWT3GjRTBER8TRKbmpJwfHz3DiGgZ9mt1RkaN3U3DgKitUtJSIinkbJTS0pHQpeUnOTdXqzEzs4uqWO5hWVW5zT1TLULSUiIh5KyY2rGAYc3QuH1gKVLL+QfXrrSjmEB/jgXbIQZ1pO7XVNObql1HIjIiKeRsmNq2yfC692h+8nAsfNc1NcALmHzeNOs6DYarU4R0zV5lw3jtFSqrkRERFPo+TGVSI7mz8PbwVbUZnRUl6QnWzu8/KFwCan/1G1vARDYbHduTCnuqVERMTTKLlxlfAW4BcK9iJI215aUOxtLd8l5YJ1miJqeQmGjGNml5TVAqH+Sm5ERMSzKLlxFYsFos4y36dschb7+nlbyxQTn16XlENkLS/BkFEyUioswAerVYtmioiIZ1Fy40rO5GZj+ZobFyc3EcGOWYprp1sqPVdLL4iIiOdScuNKZVpuSkdLeblspJSDo+WmtmYpdg4DVzGxiIh4ICU3rhTVxfyZvLH8JH6u7paq5Zob54rgKiYWEREPpOTGlRwjpnKS8Ss4ApTMc+NIblzVclMyWmp/eh7HCm0uuWZZmuNGREQ8mZIbV/ILhkatAIgp2G1u8vYqXVfqNGcndugQHUJ0qD8ZeUX855dtLrlmWRlquREREQ+m5MbVSupumhXsAcDPy1I6z81privl4O/jxdQruwLw0Z97WL4n3SXXdXAWFKvmRkREPJCSG1crqbtpWbQLgEBbBtjMZIHgaJd9zHkdIvl7n+YYBtz/9TqXdk+Vriul5EZERDyPkhtXizaTm1a2vQAEF6SY24Miwdu1ycLDozoTHerP3iN5vPDLVpddVwXFIiLiyZTcuFpJt1S8kYgXNgLzHWtKuaZLqqywAB9n99THf+51WfeUCopFRMSTKblxtfB48AnCjyLiLckE5Je03IS4Zhj48cp2T/3LRd1TRzWJn4iIeDAlN65mtUKUOSS8s2UffsccxcS1k9wAPHJxZ2LC/Nl3JI9Pl+49rWvZ7QaZx0q6pYLULSUiIp5HyU0tMEqKijta9+OT69qRUpUJ9ffhrvPbAfD1qgMYhnHK18rKL8Jecnp4gFpuRETE8yi5qQX2ksn8OloS8c6t3W4ph4u7x+DnbWVHag7rD2Se8nUcxcTBft7miuYiIiIeRk+vWlDQpCS5se7HK7dkXala7JYCs/Xmwi7mUPOvVx045es45rgJ10gpERHxUEpuakF+ow4ANLMcwZJuTuZX28kNwFW9mwPww7pD5BedWmGxY46bxprAT0REPJSSm1qQ7xVMoj0CAIutZHFLF60rdSID2zQlNsyfzGNFJGxJPaVrOLqlNAxcREQ8lZKbWlBYbGer0aJ0g28w+IfW+ud6WS1c0ctsvZm1KvGUrlE6O7G6pURExDMpuakFBcV2thhxpRvqoEvK4cqSrqnfth8mJSu/xucf1dILIiLi4ZTc1IKCYhtb7C1LN9RBl5RDq6ZB9GnZCLsB3645WOPzDx49BqigWEREPJeSm1pQcHy3VB223EBpYXFN57zZm5bLj+vN0V1nt25SK7GJiIjUNiU3taCgyM4+I4p8Srp26ji5GdUtBn8fKztTc1hXgzlv/jNvG8V2g3PbRyi5ERERj6XkphYU2mzYsbLfO97cUIfdUgAh/j5c1MX8zK+rWVi8NjGDOeuTsFjgwYs61mZ4IiIitUrJTS0oKLID8HPQ5RDXH9pfWOcxOLqmZq08wLrEjBMeaxgGU3/aAsAVPZvTKab2R3aJiIjUFiU3taCg2ExuVoYOgxvnQXjcSc5wvQGtm3BehwgKiu3c+MlKDhzNq/LYBVtTWbYnHV9vK/93Qfs6jFJERMT1lNzUgoJic3ZgXy/33V6r1cLr/+hFx+gQ0nIKuOHjFWTlF1U4rthm57mftwJww6BWxIYH1HWoIiIiLqXkphYUlrTc+Pm49/YG+3nz0YS+RIb4sT0lhztnrKbIZi93zNerDrAjNYfwQB9uH9rGTZGKiIi4jre7A2iIHN1Sft5ebo4EYsIC+PD6vlw9fSm/70jjwW82MKBNE3akZLMjNYfle9IBuOv8doQFaG4bERHxfEpuakFpclM/Gsa6NAvj9bE9ufmzlXyz+gDfrC6/anjnmFD+eXaLKs4WERHxLEpuakFByYrcvvUkuQEY3jmKZy/vyluLdtI8PJB2UcG0iwqhXWQwPeLC60Urk4iIiCsouakFBbb61XLjMLZfC8b2UwuNiIg0bPXr6dtAOOa5UWuIiIhI3VNyUwvqW82NiIjImURP31rgnOdGyY2IiEid09O3FqjlRkRExH309K0FpZP4qeZGRESkrim5qQVquREREXEfPX1rQX2c50ZERORMoadvLahPyy+IiIicaZTc1IJCdUuJiIi4jdufvm+++Sbx8fH4+/vTv39/li9ffsLjMzIyuPPOO4mJicHPz4/27dvz008/1VG01eMYCq7kRkREpO65dfmFmTNnMnnyZKZPn07//v155ZVXGDFiBNu2bSMyMrLC8YWFhfztb38jMjKSr7/+mmbNmrFv3z7Cw8PrPvgTKNBoKREREbdxa3Izbdo0br75ZiZMmADA9OnTmTNnDh9++CEPPvhgheM//PBD0tPT+fPPP/Hx8QEgPj6+LkOuFkdy4+ullhsREZG65ranb2FhIatWrWL48OGlwVitDB8+nKVLl1Z6zg8//MCAAQO48847iYqKokuXLjz77LPYbLYqP6egoICsrKxyr9rmGC3l56PkRkREpK657emblpaGzWYjKiqq3PaoqCiSk5MrPWf37t18/fXX2Gw2fvrpJx599FFeeuklnn766So/Z+rUqYSFhTlfcXFxLv0elSmsp6uCi4iInAk86ulrt9uJjIzk3XffpXfv3owZM4aHH36Y6dOnV3nOlClTyMzMdL4SExNrNUbDMDQUXERExI3cVnPTtGlTvLy8SElJKbc9JSWF6OjoSs+JiYnBx8cHL6/SpKFTp04kJydTWFiIr69vhXP8/Pzw8/NzbfAnUGQzMAzzvSbxExERqXtue/r6+vrSu3dvEhISnNvsdjsJCQkMGDCg0nMGDRrEzp07sdvtzm3bt28nJiam0sTGHRzDwEHdUiIiIu7g1qfv5MmTee+99/jkk0/YsmULt99+O7m5uc7RU+PGjWPKlCnO42+//XbS09O5++672b59O3PmzOHZZ5/lzjvvdNdXqMAxgR8ouREREXEHtw4FHzNmDIcPH+axxx4jOTmZHj16MHfuXGeR8f79+7FaSxOEuLg4fvnlF+699166detGs2bNuPvuu3nggQfc9RUqcA4D97ZisVjcHI2IiMiZx2IYjgqRM0NWVhZhYWFkZmYSGhrq8uvvScvlvBcXEeLnzYZ/j3D59UVERM5ENXl+q9/ExZxLL2iOGxEREbfQE9jFCjUMXERExK2U3LhYgVYEFxERcSs9gV2soKi0oFhERETqnp7ALuasuVFyIyIi4hZ6AruYll4QERFxLyU3LuYsKNZoKREREbfQE9jF1C0lIiLiXnoCu1jZGYpFRESk7ukJ7GKO0VKquREREXEPJTcuVmjTPDciIiLupCewixUUqeZGRETEnfQEdjHV3IiIiLiXnsAupnluRERE3EvJjYtpKLiIiIh76QnsYgWaxE9ERMSt9AR2MXVLiYiIuJeSGxfTquAiIiLupSewi6nmRkRExL30BHaxQnVLiYiIuJWSGxcrrbnRrRUREXEHPYFdTJP4iYiIuJeewC6mmhsRERH30hPYxZw1Nz6quREREXEHJTcuppobERER99IT2MUcq4Kr5kZERMQ99AR2MbXciIiIuJeewC5kGIaWXxAREXEzJTcuVGQznO+1cKaIiIh76AnsQo5h4KBuKREREXfRE9iFHF1SAL5eurUiIiLuoCewC5Wdndhisbg5GhERkTOTkhsXKtRIKREREbfTU9iFSpde0EgpERERd1Fy40IFRWq5ERERcTc9hV1IE/iJiIi4n57CLuToltLSCyIiIu6jp7ALaUVwERER91Ny40LObinNcSMiIuI2egq7kHO0lJZeEBERcRs9hV1Io6VERETcT09hFyq0aUVwERERd1Ny40JquREREXE/PYVdSEPBRURE3E9PYRfSJH4iIiLup6ewC2meGxEREfdTcuNCarkRERFxPz2FXchZc6NJ/ERERNxGT2EXco6W0iR+IiIibqOnsAuVdkup5kZERMRdlNy4kGpuRERE3E9PYRfSPDciIiLup6ewC6lbSkRExP2U3LiQuqVERETcT09hFyqdxE+3VURExF30FHYhR82NuqVERETcR8mNCznmuVFBsYiIiPvoKexCqrkRERFxv3rxFH7zzTeJj4/H39+f/v37s3z58iqP/fjjj7FYLOVe/v7+dRht1Uq7perFbRURETkjuf0pPHPmTCZPnszjjz/O6tWr6d69OyNGjCA1NbXKc0JDQ0lKSnK+9u3bV4cRV02rgouIiLif25ObadOmcfPNNzNhwgQ6d+7M9OnTCQwM5MMPP6zyHIvFQnR0tPMVFRVVhxFXzjAMZ7eUFs4UERFxH7c+hQsLC1m1ahXDhw93brNarQwfPpylS5dWeV5OTg4tW7YkLi6OSy+9lE2bNtVFuCdUaLM732souIiIiPu49SmclpaGzWar0PISFRVFcnJyped06NCBDz/8kO+//57PP/8cu93OwIEDOXDgQKXHFxQUkJWVVe5VGxytNqCaGxEREXfyuKfwgAEDGDduHD169ODcc89l9uzZRERE8M4771R6/NSpUwkLC3O+4uLiaiWuwjLJjbqlRERE3MetT+GmTZvi5eVFSkpKue0pKSlER0dX6xo+Pj707NmTnTt3Vrp/ypQpZGZmOl+JiYmnHXdlnPU23lYsFkutfIaIiIicnFuTG19fX3r37k1CQoJzm91uJyEhgQEDBlTrGjabjQ0bNhATE1Ppfj8/P0JDQ8u9akNBkYaBi4iI1Afe7g5g8uTJjB8/nj59+tCvXz9eeeUVcnNzmTBhAgDjxo2jWbNmTJ06FYAnn3ySs88+m7Zt25KRkcF//vMf9u3bx0033eTOr6EVwUVEROoJtyc3Y8aM4fDhwzz22GMkJyfTo0cP5s6d6ywy3r9/P1ZraWvI0aNHufnmm0lOTqZRo0b07t2bP//8k86dO7vrKwBl5rhRy42IiIhbWQzDMNwdRF3KysoiLCyMzMxMl3ZRrdp3lOs+WEaz8ADmTz7XZdcVERGRmj2/3d5y01D0btmIzU9e6O4wREREznjqQxEREZEGRcmNiIiINChKbkRERKRBUXIjIiIiDYqSGxEREWlQlNyIiIhIg6LkRkRERBoUJTciIiLSoCi5ERERkQZFyY2IiIg0KEpuREREpEFRciMiIiINipIbERERaVCU3IiIiEiD4u3uAOqaYRgAZGVluTkSERERqS7Hc9vxHD+RMy65yc7OBiAuLs7NkYiIiEhNZWdnExYWdsJjLEZ1UqAGxG63c+jQIUJCQrBYLC69dlZWFnFxcSQmJhIaGurSa0sp3ee6oftcN3Sf647udd2orftsGAbZ2dnExsZitZ64quaMa7mxWq00b968Vj8jNDRU/+PUAd3nuqH7XDd0n+uO7nXdqI37fLIWGwcVFIuIiEiDouRGREREGhQlNy7k5+fH448/jp+fn7tDadB0n+uG7nPd0H2uO7rXdaM+3OczrqBYREREGja13IiIiEiDouRGREREGhQlNyIiItKgKLkRERGRBkXJjYu8+eabxMfH4+/vT//+/Vm+fLm7Q/JoU6dOpW/fvoSEhBAZGclll13Gtm3byh2Tn5/PnXfeSZMmTQgODubKK68kJSXFTRE3DM899xwWi4V77rnHuU332XUOHjzIP//5T5o0aUJAQABdu3Zl5cqVzv2GYfDYY48RExNDQEAAw4cPZ8eOHW6M2PPYbDYeffRRWrVqRUBAAG3atOGpp54qtx6R7nPN/fbbb4wePZrY2FgsFgvfffdduf3Vuafp6elce+21hIaGEh4ezo033khOTk7tBGzIafvyyy8NX19f48MPPzQ2bdpk3HzzzUZ4eLiRkpLi7tA81ogRI4yPPvrI2Lhxo7F27Vpj5MiRRosWLYycnBznMbfddpsRFxdnJCQkGCtXrjTOPvtsY+DAgW6M2rMtX77ciI+PN7p162bcfffdzu26z66Rnp5utGzZ0rj++uuNZcuWGbt37zZ++eUXY+fOnc5jnnvuOSMsLMz47rvvjHXr1hmXXHKJ0apVK+PYsWNujNyzPPPMM0aTJk2MH3/80dizZ48xa9YsIzg42Hj11Vedx+g+19xPP/1kPPzww8bs2bMNwPj222/L7a/OPb3wwguN7t27G3/99Zfx+++/G23btjXGjh1bK/EquXGBfv36GXfeeafzd5vNZsTGxhpTp051Y1QNS2pqqgEYixcvNgzDMDIyMgwfHx9j1qxZzmO2bNliAMbSpUvdFabHys7ONtq1a2fMnz/fOPfcc53Jje6z6zzwwAPG4MGDq9xvt9uN6Oho4z//+Y9zW0ZGhuHn52f897//rYsQG4RRo0YZN9xwQ7ltV1xxhXHttdcahqH77ArHJzfVuaebN282AGPFihXOY37++WfDYrEYBw8edHmM6pY6TYWFhaxatYrhw4c7t1mtVoYPH87SpUvdGFnDkpmZCUDjxo0BWLVqFUVFReXue8eOHWnRooXu+ym48847GTVqVLn7CbrPrvTDDz/Qp08frr76aiIjI+nZsyfvvfeec/+ePXtITk4ud6/DwsLo37+/7nUNDBw4kISEBLZv3w7AunXrWLJkCRdddBGg+1wbqnNPly5dSnh4OH369HEeM3z4cKxWK8uWLXN5TGfcwpmulpaWhs1mIyoqqtz2qKgotm7d6qaoGha73c4999zDoEGD6NKlCwDJycn4+voSHh5e7tioqCiSk5PdEKXn+vLLL1m9ejUrVqyosE/32XV2797N22+/zeTJk3nooYdYsWIFkyZNwtfXl/HjxzvvZ2V/l+heV9+DDz5IVlYWHTt2xMvLC5vNxjPPPMO1114LoPtcC6pzT5OTk4mMjCy339vbm8aNG9fKfVdyI/XenXfeycaNG1myZIm7Q2lwEhMTufvuu5k/fz7+/v7uDqdBs9vt9OnTh2effRaAnj17snHjRqZPn8748ePdHF3D8dVXXzFjxgy++OILzjrrLNauXcs999xDbGys7vMZRN1Sp6lp06Z4eXlVGD2SkpJCdHS0m6JqOCZOnMiPP/7IwoULad68uXN7dHQ0hYWFZGRklDte971mVq1aRWpqKr169cLb2xtvb28WL17Ma6+9hre3N1FRUbrPLhITE0Pnzp3LbevUqRP79+8HcN5P/V1yev71r3/x4IMPcs0119C1a1euu+467r33XqZOnQroPteG6tzT6OhoUlNTy+0vLi4mPT29Vu67kpvT5OvrS+/evUlISHBus9vtJCQkMGDAADdG5tkMw2DixIl8++23LFiwgFatWpXb37t3b3x8fMrd923btrF//37d9xoYNmwYGzZsYO3atc5Xnz59uPbaa53vdZ9dY9CgQRWmM9i+fTstW7YEoFWrVkRHR5e711lZWSxbtkz3ugby8vKwWss/2ry8vLDb7YDuc22ozj0dMGAAGRkZrFq1ynnMggULsNvt9O/f3/VBubxE+Qz05ZdfGn5+fsbHH39sbN682bjllluM8PBwIzk52d2heazbb7/dCAsLMxYtWmQkJSU5X3l5ec5jbrvtNqNFixbGggULjJUrVxoDBgwwBgwY4MaoG4ayo6UMQ/fZVZYvX254e3sbzzzzjLFjxw5jxowZRmBgoPH55587j3nuueeM8PBw4/vvvzfWr19vXHrppRqiXEPjx483mjVr5hwKPnv2bKNp06bG/fff7zxG97nmsrOzjTVr1hhr1qwxAGPatGnGmjVrjH379hmGUb17euGFFxo9e/Y0li1bZixZssRo166dhoLXd6+//rrRokULw9fX1+jXr5/x119/uTskjwZU+vroo4+cxxw7dsy44447jEaNGhmBgYHG5ZdfbiQlJbkv6Abi+ORG99l1/ve//xldunQx/Pz8jI4dOxrvvvtuuf12u9149NFHjaioKMPPz88YNmyYsW3bNjdF65mysrKMu+++22jRooXh7+9vtG7d2nj44YeNgoIC5zG6zzW3cOHCSv9OHj9+vGEY1bunR44cMcaOHWsEBwcboaGhxoQJE4zs7OxaiddiGGWmbRQRERHxcKq5ERERkQZFyY2IiIg0KEpuREREpEFRciMiIiINipIbERERaVCU3IiIiEiDouRGREREGhQlNyJyxomPj+eVV15xdxgiUkuU3IhIrbr++uu57LLLABg6dCj33HNPnX32xx9/THh4eIXtK1as4JZbbqmzOESkbnm7OwARkZoqLCzE19f3lM+PiIhwYTQiUt+o5UZE6sT111/P4sWLefXVV7FYLFgsFvbu3QvAxo0bueiiiwgODiYqKorrrruOtLQ057lDhw5l4sSJ3HPPPTRt2pQRI0YAMG3aNLp27UpQUBBxcXHccccd5OTkALBo0SImTJhAZmam8/OeeOIJoGK31P79+7n00ksJDg4mNDSUv//976SkpDj3P/HEE/To0YPPPvuM+Ph4wsLCuOaaa8jOzq7dmyYip0TJjYjUiVdffZUBAwZw8803k5SURFJSEnFxcWRkZHD++efTs2dPVq5cydy5c0lJSeHvf/97ufM/+eQTfH19+eOPP5g+fToAVquV1157jU2bNvHJJ5+wYMEC7r//fgAGDhzIK6+8QmhoqPPz7rvvvgpx2e12Lr30UtLT01m8eDHz589n9+7djBkzptxxu3bt4rvvvuPHH3/kxx9/ZPHixTz33HO1dLdE5HSoW0pE6kRYWBi+vr4EBgYSHR3t3P7GG2/Qs2dPnn32Wee2Dz/8kLi4OLZv30779u0BaNeuHS+88EK5a5at34mPj+fpp5/mtttu46233sLX15ewsDAsFku5zzteQkICGzZsYM+ePcTFxQHw6aefctZZZ7FixQr69u0LmEnQxx9/TEhICADXXXcdCQkJPPPMM6d3Y0TE5dRyIyJutW7dOhYuXEhwcLDz1bFjR8BsLXHo3bt3hXN//fVXhg0bRrNmzQgJCeG6667jyJEj5OXlVfvzt2zZQlxcnDOxAejcuTPh4eFs2bLFuS0+Pt6Z2ADExMSQmppao+8qInVDLTci4lY5OTmMHj2a559/vsK+mJgY5/ugoKBy+/bu3cvFF1/M7bffzjPPPEPjxo1ZsmQJN954I4WFhQQGBro0Th8fn3K/WywW7Ha7Sz9DRFxDyY2I1BlfX19sNlu5bb169eKbb74hPj4eb+/q/5W0atUq7HY7L730Elar2Qj91VdfnfTzjtepUycSExNJTEx0tt5s3ryZjIwMOnfuXO14RKT+ULeUiNSZ+Ph4li1bxt69e0lLS8Nut3PnnXeSnp7O2LFjWbFiBbt27eKXX35hwoQJJ0xM2rZtS1FREa+//jq7d+/ms88+cxYal/28nJwcEhISSEtLq7S7avjw4XTt2pVrr72W1atXs3z5csaNG8e5555Lnz59XH4PRKT2KbkRkTpz33334eXlRefOnYmIiGD//v3Exsbyxx9/YLPZuOCCC+jatSv33HMP4eHhzhaZynTv3p1p06bx/PPP06VLF2bMmMHUqVPLHTNw4EBuu+02xowZQ0RERIWCZDC7l77//nsaNWrEOeecw/Dhw2ndujUzZ850+fcXkbphMQzDcHcQIiIiIq6ilhsRERFpUJTciIiISIOi5EZEREQaFCU3IiIi0qAouREREZEGRcmNiIiINChKbkRERKRBUXIjIiIiDYqSGxEREWlQlNyIiIhIg6LkRkRERBoUJTciIiLSoPw/isQReZv9AhkAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_save = {\n",
        "    'accuracy': client_accs,\n",
        "    'loss': client_losses}\n",
        "\n",
        "with open('100_dual.json', 'w') as f:\n",
        "    json.dump(to_save, f)"
      ],
      "metadata": {
        "id": "IEwjEHJJXmG_"
      },
      "id": "IEwjEHJJXmG_",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5qTjOfEZXsC1"
      },
      "id": "5qTjOfEZXsC1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}